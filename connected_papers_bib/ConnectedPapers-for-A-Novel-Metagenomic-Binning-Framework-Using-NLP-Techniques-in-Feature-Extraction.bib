@article{3fa1dabc312521784922ff8fc0de497544cb6c07,
title = {A Novel Metagenomic Binning Framework Using NLP Techniques in Feature Extraction},
year = {2022},
url = {https://www.semanticscholar.org/paper/3fa1dabc312521784922ff8fc0de497544cb6c07},
abstract = {Without traditional cultures, metagenomics studies the microorganisms sampled from the environment. In those studies, the binning step results serve as an input for the next step of metagenomic projects such as assembly and annotation. The main challenging issue of this process is due to the lack of explicit features of metagenomic reads, especially in the case of short-read datasets. There are two approaches, namely, supervised and unsupervised learning. Unfortunately, only about 1% of microorganisms in nature is annotated. That can cause problems for supervised approaches when an under-study dataset contains unknown species. It is well-known that the main challenging issue of this process is due to the lack of explicit features of metagenomic reads, especially in the case of short-read datasets. Previous studies usually assumed that reads in a taxonomic label have similar k-mer distributions. Our new method is to use Natural Language Processing (NLP) techniques in generating feature vectors. Additionally, the paper presents a comprehensive unsupervised framework in order to apply different embeddings categorized as notable NLP techniques in topic modeling and sentence embedding. The experimental results present our proposed approach’s comparative performance with other previous studies on simulated datasets, showing the feasibility of applying NLP for metagenomic binning. The program can be found at https://github.com/vandinhvyphuong/NLPBimeta.},
author = {Viet Toan Tran and Hoang D. Quach and Phuong V. D. Van and Van Hoai Tran},
doi = {10.2197/ipsjtbio.15.1},
}

@article{2cfbab613f57f6d20350463a43b5fe4b28b51017,
title = {Reconstructing single genomes from complex microbial communities},
year = {2016},
url = {https://www.semanticscholar.org/paper/2cfbab613f57f6d20350463a43b5fe4b28b51017},
abstract = {Abstract High throughput next generation sequencing technologies have enabled cultivation-independent approaches to study microbial communities in environmental samples. To date much of functional metagenomics has been limited to the gene or pathway level. Recent breakthroughs in metagenome binning have made it feasible to reconstruct high quality, individual microbial genomes from complex communities with thousands of species. In this review we aim to compare several automated metagenome binning software tools for their performance, and provide a practical guide for the metagenomics research community to carry out successful binning analyses.},
author = {Dongwan D. Kang and E. Rubin and Zhong Wang},
journal = {it - Information Technology},
volume = {58},
pages = {133 - 139},
doi = {10.1515/itit-2016-0011},
}

@article{4050dbffbaf3859403f40c3e49473b1412571486,
title = {GraphBin2: Refined and Overlapped Binning of Metagenomic Contigs Using Assembly Graphs},
year = {2020},
url = {https://www.semanticscholar.org/paper/4050dbffbaf3859403f40c3e49473b1412571486},
abstract = {Metagenomic sequencing allows us to study structure, diversity and ecology in microbial communities without the necessity of obtaining pure cultures. In many metagenomics studies, the reads obtained from metagenomics sequencing are first assembled into longer contigs and these contigs are then binned into clusters of contigs where contigs in a cluster are expected to come from the same species. As different species may share common sequences in their genomes, one assembled contig may belong to multiple species. However, existing tools for contig binning only support non-overlapped binning, i.e., each contig is assigned to at most one bin (species). In this paper, we introduce GraphBin2 which refines the binning results obtained from existing tools and, more importantly, is able to assign contigs to multiple bins. GraphBin2 uses the connectivity and coverage information from assembly graphs to adjust existing binning results on contigs and to infer contigs shared by multiple species. Experimental results on both simulated and real datasets demonstrate that GraphBin2 not only improves binning results of existing tools but also supports to assign contigs to multiple bins. 2012 ACM Subject Classification Applied computing → Bioinformatics; Applied computing → Computational genomics},
author = {V. Mallawaarachchi and A. Wickramarachchi and Yu Lin},
doi = {10.4230/LIPIcs.WABI.2020.8},
}

@article{163cb3ce781a08e8f93ebd1d4cca3a4b72ec9010,
title = {COCACOLA: binning metagenomic contigs using sequence COmposition, read CoverAge, CO‐alignment and paired‐end read LinkAge},
year = {2016},
url = {https://www.semanticscholar.org/paper/163cb3ce781a08e8f93ebd1d4cca3a4b72ec9010},
abstract = {Motivation: The advent of next‐generation sequencing technologies enables researchers to sequence complex microbial communities directly from the environment. Because assembly typically produces only genome fragments, also known as contigs, instead of an entire genome, it is crucial to group them into operational taxonomic units (OTUs) for further taxonomic profiling and down‐streaming functional analysis. OTU clustering is also referred to as binning. We present COCACOLA, a general framework automatically bin contigs into OTUs based on sequence composition and coverage across multiple samples. Results: The effectiveness of COCACOLA is demonstrated in both simulated and real datasets in comparison with state‐of‐art binning approaches such as CONCOCT, GroopM, MaxBin and MetaBAT. The superior performance of COCACOLA relies on two aspects. One is using L1 distance instead of Euclidean distance for better taxonomic identification during initialization. More importantly, COCACOLA takes advantage of both hard clustering and soft clustering by sparsity regularization. In addition, the COCACOLA framework seamlessly embraces customized knowledge to facilitate binning accuracy. In our study, we have investigated two types of additional knowledge, the co‐alignment to reference genomes and linkage of contigs provided by paired‐end reads, as well as the ensemble of both. We find that both co‐alignment and linkage information further improve binning in the majority of cases. COCACOLA is scalable and faster than CONCOCT, GroopM, MaxBin and MetaBAT. Availability and implementation: The software is available at https://github.com/younglululu/COCACOLA. Contact: fsun@usc.edu Supplementary information: Supplementary data are available at Bioinformatics online.},
author = {Yang Young Lu and Ting Chen and J. Fuhrman and Fengzhu Sun},
journal = {Bioinformatics},
volume = {33},
pages = {791–798},
doi = {10.1093/bioinformatics/btw290},
pmid = {27256312},
arxivid = {1604.02512},
}

@article{2095490975323f9f0353281826374501ba9e158f,
title = {Accurate binning of metagenomic contigs via automated clustering sequences using information of genomic signatures and marker genes},
year = {2016},
url = {https://www.semanticscholar.org/paper/2095490975323f9f0353281826374501ba9e158f},
abstract = {Metagenomics, the application of shotgun sequencing, facilitates the reconstruction of the genomes of individual species from natural environments. A major challenge in the genome recovery domain is to agglomerate or ‘bin’ sequences assembled from metagenomic reads into individual groups. Metagenomic binning without consideration of reference sequences enables the comprehensive discovery of new microbial organisms and aids in the microbial genome reconstruction process. Here we present MyCC, an automated binning tool that combines genomic signatures, marker genes and optional contig coverages within one or multiple samples, in order to visualize the metagenomes and to identify the reconstructed genomic fragments. We demonstrate the superior performance of MyCC compared to other binning tools including CONCOCT, GroopM, MaxBin and MetaBAT on both synthetic and real human gut communities with a small sample size (one to 11 samples), as well as on a large metagenome dataset (over 250 samples). Moreover, we demonstrate the visualization of metagenomes in MyCC to aid in the reconstruction of genomes from distinct bins. MyCC is freely available at http://sourceforge.net/projects/sb2nhri/files/MyCC/.},
author = {Hsin-Hung Lin and Yu-Chieh Liao},
journal = {Scientific Reports},
volume = {6},
pages = {},
doi = {10.1038/srep24175},
pmid = {27067514},
}

@article{d319ca65f99bfc5602b15eb8fe741d1e2e03f33a,
title = {MaxBin 2.0: an automated binning algorithm to recover genomes from multiple metagenomic datasets},
year = {2016},
url = {https://www.semanticscholar.org/paper/d319ca65f99bfc5602b15eb8fe741d1e2e03f33a},
abstract = {UNLABELLED
The recovery of genomes from metagenomic datasets is a critical step to defining the functional roles of the underlying uncultivated populations. We previously developed MaxBin, an automated binning approach for high-throughput recovery of microbial genomes from metagenomes. Here we present an expanded binning algorithm, MaxBin 2.0, which recovers genomes from co-assembly of a collection of metagenomic datasets. Tests on simulated datasets revealed that MaxBin 2.0 is highly accurate in recovering individual genomes, and the application of MaxBin 2.0 to several metagenomes from environmental samples demonstrated that it could achieve two complementary goals: recovering more bacterial genomes compared to binning a single sample as well as comparing the microbial community composition between different sampling environments.


AVAILABILITY AND IMPLEMENTATION
MaxBin 2.0 is freely available at http://sourceforge.net/projects/maxbin/ under BSD license.},
author = {Yu-Wei Wu and B. Simmons and S. Singer},
journal = {Bioinformatics},
volume = {32 4},
pages = {
          605-7
        },
doi = {10.1093/bioinformatics/btv638},
pmid = {26515820},
}

@article{c37cc9c75cead9f24bbf6197ff4c9b12c4107b51,
title = {Recovery of genomes from metagenomes via a dereplication, aggregation and scoring strategy},
year = {2018},
url = {https://www.semanticscholar.org/paper/c37cc9c75cead9f24bbf6197ff4c9b12c4107b51},
abstract = {Microbial communities are critical to ecosystem function. A key objective of metagenomic studies is to analyse organism-specific metabolic pathways and reconstruct community interaction networks. This requires accurate assignment of assembled genome fragments to genomes. Existing binning methods often fail to reconstruct a reasonable number of genomes and report many bins of low quality and completeness. Furthermore, the performance of existing algorithms varies between samples and biotopes. Here, we present a dereplication, aggregation and scoring strategy, DAS Tool, that combines the strengths of a flexible set of established binning algorithms. DAS Tool applied to a constructed community generated more accurate bins than any automated method. Indeed, when applied to environmental and host-associated samples of different complexity, DAS Tool recovered substantially more near-complete genomes, including previously unreported lineages, than any single binning method alone. The ability to reconstruct many near-complete genomes from metagenomics data will greatly advance genome-centric analyses of ecosystems.Here the authors present a tool that enables a flexible set of existing binning algorithms to be combined, resulting in improved binning accuracy and the recovery of more near-complete genomes from metagenomes compared to standalone methods.},
author = {C. Sieber and Alexander J. Probst and A. Sharrar and Brian C. Thomas and M. Hess and S. Tringe and J. Banfield},
journal = {Nature Microbiology},
volume = {3},
pages = {836 - 843},
doi = {10.1038/s41564-018-0171-1},
pmid = {29807988},
}

@article{fa92c9dc6d9fdebeb6e06786b0fb9c4784d18dc0,
title = {Bioinformatics strategies for taxonomy independent binning and visualization of sequences in shotgun metagenomics},
year = {2016},
url = {https://www.semanticscholar.org/paper/fa92c9dc6d9fdebeb6e06786b0fb9c4784d18dc0},
abstract = {One of main steps in a study of microbial communities is resolving their composition, diversity and function. In the past, these issues were mostly addressed by the use of amplicon sequencing of a target gene because of reasonable price and easier computational postprocessing of the bioinformatic data. With the advancement of sequencing techniques, the main focus shifted to the whole metagenome shotgun sequencing, which allows much more detailed analysis of the metagenomic data, including reconstruction of novel microbial genomes and to gain knowledge about genetic potential and metabolic capacities of whole environments. On the other hand, the output of whole metagenomic shotgun sequencing is mixture of short DNA fragments belonging to various genomes, therefore this approach requires more sophisticated computational algorithms for clustering of related sequences, commonly referred to as sequence binning. There are currently two types of binning methods: taxonomy dependent and taxonomy independent. The first type classifies the DNA fragments by performing a standard homology inference against a reference database, while the latter performs the reference-free binning by applying clustering techniques on features extracted from the sequences. In this review, we describe the strategies within the second approach. Although these strategies do not require prior knowledge, they have higher demands on the length of sequences. Besides their basic principle, an overview of particular methods and tools is provided. Furthermore, the review covers the utilization of the methods in context with the length of sequences and discusses the needs for metagenomic data preprocessing in form of initial assembly prior to binning.},
author = {K. Sedlář and K. Kupkova and I. Provazník},
journal = {Computational and Structural Biotechnology Journal},
volume = {15},
pages = {48 - 55},
doi = {10.1016/j.csbj.2016.11.005},
pmid = {27980708},
}

@article{ae78dbf1eb13e92c6654c2d7f96be38dde26dfba,
title = {A probabilistic model to recover individual genomes from metagenomes},
year = {2017},
url = {https://semanticscholar.org/paper/ae78dbf1eb13e92c6654c2d7f96be38dde26dfba},
abstract = {12 Shotgun metagenomics of microbial communities reveals information about strains of relevance for applications in medicine, biotechnology and ecology. Recovering their genomes is a crucial, but very challenging step, due to the complexity of the underlying biological system and technical factors. Microbial communities are heterogeneous, with oftentimes hundreds of present genomes deriving from different species or strains, all at varying abundances and with different degrees of similarity to each other and reference data. We present a versatile probabilistic model for genome recovery and analysis, which aggregates three types of information that are commonly used for genome recovery from metagenomes. As potential applications we showcase metagenome contig classification, genome sample enrichment and genome bin comparisons. The open source implementation MGLEX is available via the Python Package Index and on GitHub and can be embedded into metagenome analysis workflows and programs. 13},
author = {Johannes  Dröge and Alexander  Schönhuth and Alice C McHardy},
journal = {PeerJ Prepr.},
volume = {4},
pages = {e2626},
doi = {10.7287/peerj-cs.117v0.2/reviews/3},
}

@article{1f28f53a6f6fcba883def8f8227864602ab56000,
title = {Binning metagenomic contigs by coverage and composition},
year = {2014},
url = {https://www.semanticscholar.org/paper/1f28f53a6f6fcba883def8f8227864602ab56000},
abstract = {Shotgun sequencing enables the reconstruction of genomes from complex microbial communities, but because assembly does not reconstruct entire genomes, it is necessary to bin genome fragments. Here we present CONCOCT, a new algorithm that combines sequence composition and coverage across multiple samples, to automatically cluster contigs into genomes. We demonstrate high recall and precision on artificial as well as real human gut metagenome data sets.},
author = {J. Alneberg and Brynjar Smári Bjarnason and I. de Bruijn and M. Schirmer and J. Quick and U. Ijaz and L. Lahti and N. Loman and A. Andersson and C. Quince},
journal = {Nature Methods},
volume = {11},
pages = {1144-1146},
doi = {10.1038/nmeth.3103},
pmid = {25218180},
}

@article{4a4c4c0159b86ec0fa6a575f3b6d05e9e3768c00,
title = {A signal processing method for alignment-free metagenomic binning: multi-resolution genomic binary patterns},
year = {2019},
url = {https://www.semanticscholar.org/paper/4a4c4c0159b86ec0fa6a575f3b6d05e9e3768c00},
abstract = {Algorithms in bioinformatics use textual representations of genetic information, sequences of the characters A, T, G and C represented computationally as strings or sub-strings. Signal and related image processing methods offer a rich source of alternative descriptors as they are designed to work in the presence of noisy data without the need for exact matching. Here we introduce a method, multi-resolution local binary patterns (MLBP) adapted from image processing to extract local ‘texture’ changes from nucleotide sequence data. We apply this feature space to the alignment-free binning of metagenomic data. The effectiveness of MLBP is demonstrated using both simulated and real human gut microbial communities. Sequence reads or contigs can be represented as vectors and their ‘texture’ compared efficiently using machine learning algorithms to perform dimensionality reduction to capture eigengenome information and perform clustering (here using randomized singular value decomposition and BH-tSNE). The intuition behind our method is the MLBP feature vectors permit sequence comparisons without the need for explicit pairwise matching. We demonstrate this approach outperforms existing methods based on k-mer frequencies. The signal processing method, MLBP, thus offers a viable alternative feature space to textual representations of sequence data. The source code for our Multi-resolution Genomic Binary Patterns method can be found at https://github.com/skouchaki/MrGBP.},
author = {S. Kouchaki and Avraam Tapinos and D. Robertson},
journal = {Scientific Reports},
volume = {9},
pages = {},
doi = {10.1038/s41598-018-38197-9},
pmid = {30770850},
}

@article{1f2752f232537fa40f2a76c54b82b478f1c6f970,
title = {A framework for space-efficient read clustering in metagenomic samples},
year = {2017},
url = {https://www.semanticscholar.org/paper/1f2752f232537fa40f2a76c54b82b478f1c6f970},
abstract = {BackgroundA metagenomic sample is a set of DNA fragments, randomly extracted from multiple cells in an environment, belonging to distinct, often unknown species. Unsupervised metagenomic clustering aims at partitioning a metagenomic sample into sets that approximate taxonomic units, without using reference genomes. Since samples are large and steadily growing, space-efficient clustering algorithms are strongly needed.ResultsWe design and implement a space-efficient algorithmic framework that solves a number of core primitives in unsupervised metagenomic clustering using just the bidirectional Burrows-Wheeler index and a union-find data structure on the set of reads. When run on a sample of total length n, with m reads of maximum length ℓ each, on an alphabet of total size σ, our algorithms take O(n(t+logσ)) time and just 2n+o(n)+O(max{ℓσlogn,K logm}) bits of space in addition to the index and to the union-find data structure, where K is a measure of the redundancy of the sample and t is the query time of the union-find data structure.ConclusionsOur experimental results show that our algorithms are practical, they can exploit multiple cores by a parallel traversal of the suffix-link tree, and they are competitive both in space and in time with the state of the art.},
author = {Jarno N. Alanko and F. Cunial and Djamal Belazzougui and V. Mäkinen},
journal = {BMC Bioinformatics},
volume = {18},
pages = {},
doi = {10.1186/s12859-017-1466-6},
pmid = {28361710},
}

@article{5a4f45bdb95b3e8346784c9967d5b8edcebf0ac0,
title = {A robust statistical framework for reconstructing genomes from metagenomic data},
year = {2014},
url = {https://www.semanticscholar.org/paper/5a4f45bdb95b3e8346784c9967d5b8edcebf0ac0},
abstract = {We present software that reconstructs genomes from shotgun metagenomic sequences using a reference-independent approach. This method permits the identification of OTUs in large complex communities where many species are unknown. Binning reduces the complexity of a metagenomic dataset enabling many downstream analyses previously unavailable. In this study we developed MetaBAT, a robust statistical framework that integrates probabilistic distances of genome abundance with sequence composition for automatic binning. Applying MetaBAT to a human gut microbiome dataset identified 173 highly specific genomes bins including many representing previously unidentified species.},
author = {Dongwan D. Kang and J. Froula and R. Egan and Zhong Wang},
journal = {bioRxiv},
volume = {},
pages = {},
doi = {10.1101/011460},
}

@article{952779fa10c3bdbba775a7d051985c17b3b40892,
title = {Stable Isotope Probing: Methods and Protocols},
year = {2019},
url = {https://www.semanticscholar.org/paper/952779fa10c3bdbba775a7d051985c17b3b40892},
abstract = {Careful and thoughtful experimental design is crucial to the success of any SIP experiment. This chapter discusses the essential aspects of designing a SIP experiment, focusing primarily on DNAand RNA-SIP. The design aspects discussed here begin with considerations for carrying out the incubation, such as, the effect of choosing different stable isotopes and target biomolecules, to what degree should a labeled substrate be enriched, what concentration to use, and how long should the incubation take. Then tips and pitfalls in the technical execution of SIP are listed, including how much nucleic acids should be loaded, how many fractions to collect, and what centrifuge rotor to use. Lastly, a brief overview of the current methods for analyzing SIP data is presented, focusing on high-throughput amplicon sequencing, together with a discussion on how the choice of analysis method might affect the experimental design.},
author = {M. Dumont and M. H. García},
journal = {Stable Isotope Probing},
volume = {},
pages = {},
doi = {10.1007/978-1-4939-9721-3},
}

@article{f3e59845aa03452297e452dcf4756161311db3bd,
title = {SolidBin: improving metagenome binning with semi-supervised normalized cut},
year = {2019},
url = {https://www.semanticscholar.org/paper/f3e59845aa03452297e452dcf4756161311db3bd},
abstract = {MOTIVATION
Metagenomic contig binning is an important computational problem in metagenomic research, which aims to cluster contigs from the same genome into the same group. Unlike classical clustering problem, contig binning can utilize known relationships among some of the contigs or the taxonomic identity of some contigs. However, the current state-of-the-art contig binning methods do not make full use of the additional biological information except the coverage and sequence composition of the contigs.


RESULTS
We developed a novel contig binning method, SolidBin (Semi-supervised Spectral Normalized Cut for Binning), based on semi-supervised spectral clustering. Using sequence feature similarity and/or additional biological information, such as the reliable taxonomy assignments of some contigs, SolidBin constructs two types of prior information: must-link and cannot-link constraints. Must-link constraints mean that the pair of contigs should be clustered into the same group, while cannot-link constraints mean that the pair of contigs should be clustered in different groups. These constraints are then integrated into a classical spectral clustering approach, normalized cut (NCut), for improved contig binning. The performance of SolidBin is compared with five state-of-the-art genome binners, CONCOCT, COCACOLA, MaxBin, MetaBAT and BMC3C on five next-generation sequencing (NGS) benchmark datasets including simulated multi- and single-sample datasets and real multi-sample datasets. The experimental results show that, SolidBin has achieved the best performance in terms of F-score, ARI and NMI, especially while using the real datasets and the single sample dataset.


AVAILABILITY
https://github.com/sufforest/SolidBin.


SUPPLEMENTARY INFORMATION
Supplementary data are available at Bioinformatics online.},
author = {Ziye Wang and Zhengyang Wang and Yang Young Lu and Fengzhu Sun and Shanfeng Zhu},
journal = {Bioinformatics},
volume = {},
pages = {},
doi = {10.1093/bioinformatics/btz253},
pmid = {30977806},
}

@article{31fd955ebc0a5f915c373222531e831180faa1bf,
title = {Metagenomic Binning through Multi-resolution Genomic Binary Patterns},
year = {2016},
url = {https://www.semanticscholar.org/paper/31fd955ebc0a5f915c373222531e831180faa1bf},
abstract = {Motivation High-throughput sequencing has facilitated the analysis of complex microbial communities. Consequently, an enormous number of sequences have been generated containing various regions of bacterial and viral genomes. Image processing offers a rich source of descriptors for data analysis. Here, we introduce a feature space called multi-resolution local binary patterns (MLBP) from image processing as a feature descriptor to extract local ‘texture’ changes from nucleotide sequences. We demonstrate its applicability to the alignmentfree binning of metagenomic data. Results The effectiveness of our approach is tested using both simulated and real human gut microbial communities. We compared the performance of our method with several existing techniques that are based on k-mer frequency to show it outperforms existing techniques. In addition, we provide a time-series study of the abundance pattern of each bin to help refine the formed clusters automatically and to find relations that may exist among the clusters. Although the main aim is to introduce the use of genomic signatures using an alternative feature space (MLBP), our results show its application to the analysis of contigs from a metagenomic study. Availability The source code for our Multi-resolution Genomic Binary Patterns method can be found at https://github.com/skouchaki/MrGBP},
author = {S. Kouchaki and Avraam Tapinos and D. Robertson},
journal = {bioRxiv},
volume = {},
pages = {},
doi = {10.1101/096719},
}

@article{e7db1e96f22740121bad6f80c4ad9615bbd99d63,
title = {MetaProb 2: Improving Unsupervised Metagenomic Binning with Efficient Reads Assembly Using Minimizers},
year = {2020},
url = {https://www.semanticscholar.org/paper/e7db1e96f22740121bad6f80c4ad9615bbd99d63},
abstract = {},
author = {F. Andreace and Cinzia Pizzi and M. Comin},
doi = {10.1007/978-3-030-79290-9_2},
}

@article{0650a76f255c3ab5b5565a3fb9492a459dee216e,
title = {A generalized lattice model for clustering metagenomic sequences},
year = {2015},
url = {https://www.semanticscholar.org/paper/0650a76f255c3ab5b5565a3fb9492a459dee216e},
abstract = {Metagenomics involves the analysis of genomes of microorganisms sampled directly from their environment. Next Generation Sequencing (NGS) technologies allow a high-throughput sampling of small segments from genomes in the metagenome to generate a large number of reads. In order to study the properties and relationships of the microorganisms present, clustering of the sampled reads into groups of similar species is important. Clustering can be performed either by mapping the sampled reads to known sequencing databases, though this hinders the discovery of new species; or based on the inherent composition of the sampled reads. We propose a two-dimensional lattice based probabilistic model for clustering metagenomic datasets. The probability of a species in the metagenome is defined as a lattice model of probabilistic distributions over short sized genomic sequences (or words). The two dimensions denote distributions for different sizes and groups of words respectively. The lattice structure allows for additional support for a node from its neighbors when the probabilistic support for the species in the current node is deemed insufficient. Unlike other popular clustering algorithms such as Scimm, our algorithm guarantees convergence. We test our algorithm on simulated metagenomic data containing bacterial species and observe more than 85% precision. We also evaluate our algorithm on an in vitro-simulated bacterial metagenome and show a better clustering even for short reads and varied abundance. The software and datasets can be downloaded from https://github.com/lattcl us/lattice-metage.},
author = {M. Mukhopadhyay and R. Malhotra and R. Acharya},
journal = {Proceedings of the 6th ACM Conference on Bioinformatics, Computational Biology and Health Informatics},
volume = {},
pages = {},
doi = {10.1145/2808719.2814843},
}

@article{05819ba4e56729f7803ac0777208be8b0b19bf17,
title = {A Generalized Lattice Based Probabilistic Approach for Metagenomic Clustering},
year = {2017},
url = {https://www.semanticscholar.org/paper/05819ba4e56729f7803ac0777208be8b0b19bf17},
abstract = {Metagenomics involves the analysis of genomes of microorganisms sampled directly from their environment. Next Generation Sequencing allows a high-throughput sampling of small segments from genomes in the metagenome to generate reads. To study the properties and relationships of the microorganisms present, clustering can be performed based on the inherent composition of the sampled reads for unknown species. We propose a two-dimensional lattice based probabilistic model for clustering metagenomic datasets. The occurrence of a species in the metagenome is estimated using a lattice of probabilistic distributions over small sized genomic sequences. The two dimensions denote distributions for different sizes and groups of words, respectively. The lattice structure allows for additional support for a node from its neighbors when the probabilistic support for the species using the parameters of the current node is deemed insufficient. We also show convergence for our algorithm. We test our algorithm on simulated metagenomic data containing bacterial species and observe more than <inline-formula><tex-math notation="LaTeX"> $85\text{percent}$</tex-math><alternatives><inline-graphic xlink:href="jha-ieq1-2563422.gif"/></alternatives> </inline-formula> precision. We also evaluate our algorithm on an <italic>in vitro</italic>-simulated bacterial metagenome and on human patient data, and show a better clustering than other algorithms even for short reads and varied abundance. The software and datasets can be downloaded from <uri>https:// github.com/lattclus/lattice-metage </uri>.},
author = {M. Jha and R. Malhotra and R. Acharya},
journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
volume = {14},
pages = {749-761},
doi = {10.1109/TCBB.2016.2563422},
pmid = {27168602},
}

@article{40a1c0c5066d03cb5613f3a2d75ecc5822371e1e,
title = {MetaCRS: unsupervised clustering of contigs with the recursive strategy of reducing metagenomic dataset’s complexity},
year = {2022},
url = {https://www.semanticscholar.org/paper/40a1c0c5066d03cb5613f3a2d75ecc5822371e1e},
abstract = {Background Metagenomics technology can directly extract microbial genetic material from the environmental samples to obtain their sequencing reads, which can be further assembled into contigs through assembly tools. Clustering methods of contigs are subsequently applied to recover complete genomes from environmental samples. The main problems with current clustering methods are that they cannot recover more high-quality genes from complex environments. Firstly, there are multiple strains under the same species, resulting in assembly of chimeras. Secondly, different strains under the same species are difficult to be classified. Thirdly, it is difficult to determine the number of strains during the clustering process. Results In view of the shortcomings of current clustering methods, we propose an unsupervised clustering method which can improve the ability to recover genes from complex environments and a new method for selecting the number of sample’s strains in clustering process. The sequence composition characteristics (tetranucleotide frequency) and co-abundance are combined to train the probability model for clustering. A new recursive method that can continuously reduce the complexity of the samples is proposed to improve the ability to recover genes from complex environments. The new clustering method was tested on both simulated and real metagenomic datasets, and compared with five state-of-the-art methods including CONCOCT, Maxbin2.0, MetaBAT, MyCC and COCACOLA. In terms of the number and quality of recovered genes from metagenomic datasets, the results show that our proposed method is more effective. Conclusions A new contigs clustering method is proposed, which can recover more high-quality genes from complex environmental samples.},
author = {Zhongjun Jiang and Xiaobo Li and Li-jie Guo},
journal = {BMC Bioinformatics},
volume = {22},
pages = {},
doi = {10.1186/s12859-021-04227-z},
pmid = {35045830},
}

@article{c533bc0fe7369dffdd2defb6ec91d1fcee7f5d93,
title = {An image processing method for metagenomic binning: multi-resolution genomic binary patterns},
year = {2017},
url = {https://www.semanticscholar.org/paper/c533bc0fe7369dffdd2defb6ec91d1fcee7f5d93},
abstract = {Bioinformatics methods typically use textual representations of genetic information, represented computationally as strings or sub-strings of the characters A, T, G and C. Image processing methods offer a rich source of alternative descriptors as they are designed to work in the presence of noisy data without the need for exact matching. We introduce a method, multi-resolution local binary patterns (MLBP) from image processing to extract local 'texture' changes from nucleotide sequence data. We apply this feature space to the alignment-free binning of metagenomic data. The effectiveness of MLBP is demonstrated using both simulated and real human gut microbial communities. The intuition behind our method is the MLBP feature vectors permit sequence comparisons without the need for explicit pairwise matching. Sequence reads or contigs can then be represented as vectors and their 'texture' compared efficiently using state-of-the-art machine learning algorithms to perform dimensionality reduction to capture eigengenome information and perform clustering (here using RSVD and BH-tSNE). We demonstrate this approach outperforms existing methods based on k-mer frequency. The image processing method, MLBP, thus offers a viable alternative feature space to textual representations of sequence data. The source code for our Multi-resolution Genomic Binary Patterns method can be found at https://github.com/skouchaki/MrGBP.},
author = {S. Kouchaki and Avraam Tapinos and D. Robertson},
journal = {bioRxiv},
volume = {},
pages = {096719},
doi = {10.1101/096719},
}

@article{13ecc4bb04ed544bea6fedaeb4c385f960461a2c,
title = {Exploiting topic modeling to boost metagenomic reads binning},
year = {2015},
url = {https://www.semanticscholar.org/paper/13ecc4bb04ed544bea6fedaeb4c385f960461a2c},
abstract = {BackgroundWith the rapid development of high-throughput technologies, researchers can sequence the whole metagenome of a microbial community sampled directly from the environment. The assignment of these metagenomic reads into different species or taxonomical classes is a vital step for metagenomic analysis, which is referred to as binning of metagenomic data.ResultsIn this paper, we propose a new method TM-MCluster for binning metagenomic reads. First, we represent each metagenomic read as a set of "k-mers" with their frequencies occurring in the read. Then, we employ a probabilistic topic model -- the Latent Dirichlet Allocation (LDA) model to the reads, which generates a number of hidden "topics" such that each read can be represented by a distribution vector of the generated topics. Finally, as in the MCluster method, we apply SKWIC -- a variant of the classical K-means algorithm with automatic feature weighting mechanism to cluster these reads represented by topic distributions.ConclusionsExperiments show that the new method TM-MCluster outperforms major existing methods, including AbundanceBin, MetaCluster 3.0/5.0 and MCluster. This result indicates that the exploitation of topic modeling can effectively improve the binning performance of metagenomic reads.},
author = {Ruichang Zhang and Zhanzhan Cheng and J. Guan and Shuigeng Zhou},
journal = {BMC Bioinformatics},
volume = {16},
pages = {S2 - S2},
doi = {10.1186/1471-2105-16-S5-S2},
pmid = {25859745},
}

@article{4b5e0738f34125e791b47d838d47ed0c153a0157,
title = {ICoVeR – an interactive visualization tool for verification and refinement of metagenomic bins},
year = {2017},
url = {https://www.semanticscholar.org/paper/4b5e0738f34125e791b47d838d47ed0c153a0157},
abstract = {BackgroundRecent advances in high-throughput sequencing allow for much deeper exploitation of natural and engineered microbial communities, and to unravel so-called “microbial dark matter” (microbes that until now have evaded cultivation). Metagenomic analyses result in a large number of genomic fragments (contigs) that need to be grouped (binned) in order to reconstruct draft microbial genomes. While several contig binning algorithms have been developed in the past 2 years, they often lack consensus. Furthermore, these software tools typically lack a provision for the visualization of data and bin characteristics.ResultsWe present ICoVeR, the Interactive Contig-bin Verification and Refinement tool, which allows the visualization of genome bins. More specifically, ICoVeR allows curation of bin assignments based on multiple binning algorithms. Its visualization window is composed of two connected and interactive main views, including a parallel coordinates view and a dimensionality reduction plot. To demonstrate ICoVeR’s utility, we used it to refine disparate genome bins automatically generated using MetaBAT, CONCOCT and MyCC for an anaerobic digestion metagenomic (AD microbiome) dataset. Out of 31 refined genome bins, 23 were characterized with higher completeness and lower contamination in comparison to their respective, automatically generated, genome bins. Additionally, to benchmark ICoVeR against a previously validated dataset, we used Sharon’s dataset representing an infant gut metagenome.ConclusionsICoVeR is an open source software package that allows curation of disparate genome bins generated with automatic binning algorithms. It is freely available under the GPLv3 license at https://git.list.lu/eScience/ICoVeR. The data management and analytical functions of ICoVeR are implemented in R, therefore the software can be easily installed on any system for which R is available. Installation and usage guide together with the example files ready to be visualized are also provided via the project wiki. ICoVeR running instance preloaded with AD microbiome and Sharon’s datasets can be accessed via the website.},
author = {B. Broeksema and M. Całusińska and F. McGee and Klaas Winter and Francesco Bongiovanni and X. Goux and P. Wilmes and P. Delfosse and Mohammad Ghoniem},
journal = {BMC Bioinformatics},
volume = {18},
pages = {},
doi = {10.1186/s12859-017-1653-5},
pmid = {28464793},
}

@article{c3a2e9a92329040713e7c5972d736243d9775ddc,
title = {GraphBin: refined binning of metagenomic contigs using assembly graphs},
year = {2020},
url = {https://www.semanticscholar.org/paper/c3a2e9a92329040713e7c5972d736243d9775ddc},
abstract = {MOTIVATION
The field of metagenomics has provided valuable insights into the structure, diversity and ecology within microbial communities. One key step in metagenomics analysis is to assemble reads into longer contigs which are then binned into groups of contigs that belong to different species present in the metagenomic sample. Binning of contigs plays an important role in metagenomics and most available binning algorithms bin contigs using genomic features such as oligonucleotide/k-mer composition and contig coverage. As metagenomic contigs are derived from the assembly process, they are output from the underlying assembly graph which contains valuable connectivity information between contigs that can be used for binning.


RESULTS
We propose GraphBin, a new binning method that makes use of the assembly graph and applies a label propagation algorithm to refine the binning result of existing tools.We show that GraphBin can make use of the assembly graphs constructed from both the de Bruijn graph and the overlap-layout-consensus approach. Moreover, we demonstrate improved experimental results from GraphBin in terms of identifying mis-binned contigs and binning of contigs discarded by existing binning tools. To the best of our knowledge, this is the first time that the information from the assembly graph has been used in a tool for the binning of metagenomic contigs.


AVAILABILITY
The source code of GraphBin is available at https://github.com/Vini2/GraphBin.


SUPPLEMENTARY INFORMATION
Supplementary data are available at Bioinformatics online.},
author = {V. Mallawaarachchi and A. Wickramarachchi and Yu Lin},
journal = {Bioinformatics},
volume = {},
pages = {},
doi = {10.1093/bioinformatics/btaa180},
pmid = {32167528},
}

@article{f050426270c34f3c80e2ebc1cbee388deb9c7b12,
title = {On Clustering Validation in Metagenomics Sequence Binning},
year = {2019},
url = {https://www.semanticscholar.org/paper/f050426270c34f3c80e2ebc1cbee388deb9c7b12},
abstract = {In clustering, one of the most challenging aspects is the validation, whose objective is to evaluate how good a clustering solution is. Sequence binning is a clustering task on metagenomic data analysis. The sequence clustering challenge is essentially putting together sequences belonging to the same genome. As a clustering problem it requires proper use of validation criteria of the discovered partitions. In sequence binning, the concepts of precision and recall, and F-measure index (external validation) are normally used as benchmark. However, on practice, information about the (sub) optimal number of cluster is unknown, so these metrics might be biased to an overestimated “ground truth”. In the case of sequence binning analysis, where the reference information about genomes is not available, how to evaluate the quality of bins resulting from a clustering solution? To answer this question we empirically study both quantitative (internal indexes) and qualitative aspects (biological soundness) while evaluating clustering solutions on the sequence binning problem. Our experimental study indicates that the number of clusters, estimated by binning algorithms, do not have as much impact on the quality of bins by means of biological soundness of the discovered clusters. The quality of the sub-optimal bins (greater than 90%) were identified in both rich and poor clustering partitions. Qualitative validation is essential for proper evaluation of a sequence binning solution, generating bins with sub-optimal quality. Internal indexes can only be used in compliance with qualitative ones as a trade-off between the number of partitions and biological soundness of its respective bins.},
author = {Paulo Oliveira and K. Souza and Ronnie Alves},
doi = {10.1007/978-3-030-46417-2_1},
}

@article{25171a35be814d1eb3ceec9422fa8cee3a6deb8e,
title = {GMeta: A Novel Algorithm to Utilize Highly Connected Components for Metagenomic Binning},
year = {2019},
url = {https://www.semanticscholar.org/paper/25171a35be814d1eb3ceec9422fa8cee3a6deb8e},
abstract = {Metagenomic binning refers to the means of clustering or assigning taxonomy to metagenomic sequences or contigs. Due to the massive abundance of organisms in metagenomic samples, the number of nucleotide sequences skyrockets, and thus leading to the complexity of binning algorithms. Unsupervised classification is gaining a reputation in recent years since the lacking of the reference database required in the reference-based methods with various state-of-the-art tools released. By manipulating the overlapping information between reads drives to the success of various unsupervised methods with extraordinary accuracy. These research practices on the evidence that the average proportion of common l-mers between genomes of different species is practically miniature when l is sufficient. This paper introduces a novel algorithm for binning metagenomic sequences without requiring reference databases by utilizing highly connected components inside a weighted overlapping graph of reads. Experimental outcomes show that the precision is improved over other well-known binning tools for both short and long sequences.},
author = {T. Pham and Van-Vinh Le and T. Lang and T. Hoai},
doi = {10.1007/978-3-030-35653-8_35},
}

@article{9678b55d07e18d523c8958d9b43fe2a858534bde,
title = {Profiling of Active Microorganisms by Stable Isotope Probing-Metagenomics.},
year = {2019},
url = {https://www.semanticscholar.org/paper/9678b55d07e18d523c8958d9b43fe2a858534bde},
abstract = {Stable isotope probing (SIP) provides researchers a culture-independent method to retrieve nucleic acids from active microbial populations performing a specific metabolic activity in complex ecosystems. In recent years, the use of the SIP method in microbial ecology studies has been accelerated. This is partly due to the advances in sequencing and bioinformatics tools, which enable fast and reliable analysis of DNA and RNA from the SIP experiments. One of these sequencing tools, metagenomics, has contributed significantly to the body of knowledge by providing data not only on taxonomy but also on the key functional genes in specific metabolic pathways and their relative abundances. In this chapter, we provide a general background on the application of the SIP-metagenomics approach in microbial ecology and a workflow for the analysis of metagenomic datasets using the most up-to-date bioinformatics tools.},
author = {E. Kröber and Ö. Eyice},
journal = {Methods in molecular biology},
volume = {2046},
pages = {
          151-161
        },
doi = {10.1007/978-1-4939-9721-3_12},
pmid = {31407303},
}

@article{ed2089232e5e4455359ef3c3793e99e1b7b085b9,
title = {MetaProb 2: Metagenomic Reads Binning Based on Assembly Using Minimizers and K-Mers Statistics},
year = {2021},
url = {https://www.semanticscholar.org/paper/ed2089232e5e4455359ef3c3793e99e1b7b085b9},
abstract = {Current technologies allow the sequencing of microbial communities directly from the environment without prior culturing. One of the major problems when analyzing a microbial sample is to taxonomically annotate its reads to identify the species it contains. The major difficulties of taxonomic analysis are the lack of taxonomically related genomes in existing reference databases, the uneven abundance ratio of species, and sequencing errors. Microbial communities can be studied with reads clustering, a process referred to as genome binning. In this study, we present MetaProb 2 an unsupervised genome binning method based on reads assembly and probabilistic k-mers statistics. The novelties of MetaProb 2 are the use of minimizers to efficiently assemble reads into unitigs and a community detection algorithm based on graph modularity to cluster unitigs and to detect representative unitigs. The effectiveness of MetaProb 2 is demonstrated in both simulated and real datasets in comparison with state-of-art binning tools such as MetaProb, AbundanceBin, Bimeta, and MetaCluster. On real datasets, it is the only one capable of producing promising results while being parsimonious with computational resources.},
author = {F. Andreace and Cinzia Pizzi and M. Comin},
journal = {Journal of computational biology : a journal of computational molecular cell biology},
volume = {},
pages = {},
doi = {10.1089/cmb.2021.0270},
pmid = {34448593},
}

@article{13a9219dab6366c4b30b098b3ec3405c3aed6912,
title = {Binning unassembled short reads based on k-mer covariance in a sparse coding framework},
year = {2019},
url = {https://www.semanticscholar.org/paper/13a9219dab6366c4b30b098b3ec3405c3aed6912},
abstract = {Sequence binning techniques enable the recovery of a growing number of genomes from complex microbial metagenomes and typically require prior metagenome assembly, incurring the computational cost and drawbacks of the latter, e.g. biases against low-abundance genomes. We present here a pre-assembly binning scheme enabling latent genomes recovery by lever-aging sparsity and non-negativity constraints, and demonstrate its efficiency by recovering low-abundance genomes from a joint analysis of microbiomes from a large population cohort (LifeLines-Deep, n=1135).},
author = {Olexiy O. Kyrgyzov and V. Prost and S. Gazut and Bruno Farcy and T. Brüls},
journal = {bioRxiv},
volume = {},
pages = {},
doi = {10.1101/599332},
}

@article{4e3a97dc04f1d122c889302368bd7f24f5f95123,
title = {MetaBAT, an efficient tool for accurately reconstructing single genomes from complex microbial communities},
year = {2015},
url = {https://www.semanticscholar.org/paper/4e3a97dc04f1d122c889302368bd7f24f5f95123},
abstract = {Grouping large genomic fragments assembled from shotgun metagenomic sequences to deconvolute complex microbial communities, or metagenome binning, enables the study of individual organisms and their interactions. Because of the complex nature of these communities, existing metagenome binning methods often miss a large number of microbial species. In addition, most of the tools are not scalable to large datasets. Here we introduce automated software called MetaBAT that integrates empirical probabilistic distances of genome abundance and tetranucleotide frequency for accurate metagenome binning. MetaBAT outperforms alternative methods in accuracy and computational efficiency on both synthetic and real metagenome datasets. It automatically forms hundreds of high quality genome bins on a very large assembly consisting millions of contigs in a matter of hours on a single node. MetaBAT is open source software and available at https://bitbucket.org/berkeleylab/metabat.},
author = {Dongwan D. Kang and J. Froula and R. Egan and Zhong Wang},
journal = {PeerJ},
volume = {3},
pages = {},
doi = {10.7717/peerj.1165},
pmid = {26336640},
}

@article{16d6d7bd9b76c9c8e41b4e63be30cc77aa023c0c,
title = {Improving contig binning of metagenomic data using d2S$$ {d}_2^S $$ oligonucleotide frequency dissimilarity},
year = {2017},
url = {https://www.semanticscholar.org/paper/16d6d7bd9b76c9c8e41b4e63be30cc77aa023c0c},
abstract = {BackgroundMetagenomics sequencing provides deep insights into microbial communities. To investigate their taxonomic structure, binning assembled contigs into discrete clusters is critical. Many binning algorithms have been developed, but their performance is not always satisfactory, especially for complex microbial communities, calling for further development.ResultsAccording to previous studies, relative sequence compositions are similar across different regions of the same genome, but they differ between distinct genomes. Generally, current tools have used the normalized frequency of k-tuples directly, but this represents an absolute, not relative, sequence composition. Therefore, we attempted to model contigs using relative k-tuple composition, followed by measuring dissimilarity between contigs using d2S$$ {d}_2^S $$. The d2S$$ {d}_2^S $$ was designed to measure the dissimilarity between two long sequences or Next-Generation Sequencing data with the Markov models of the background genomes. This method was effective in revealing group and gradient relationships between genomes, metagenomes and metatranscriptomes. With many binning tools available, we do not try to bin contigs from scratch. Instead, we developed d2SBin$$ {d}_2^S\mathrm{Bin} $$ to adjust contigs among bins based on the output of existing binning tools for a single metagenomic sample. The tool is taxonomy-free and depends only on k-tuples. To evaluate the performance of d2SBin$$ {d}_2^S\mathrm{Bin} $$, five widely used binning tools with different strategies of sequence composition or the hybrid of sequence composition and abundance were selected to bin six synthetic and real datasets, after which d2SBin$$ {d}_2^S\mathrm{Bin} $$ was applied to adjust the binning results. Our experiments showed that d2SBin$$ {d}_2^S\mathrm{Bin} $$ consistently achieves the best performance with tuple length k = 6 under the independent identically distributed (i.i.d.) background model. Using the metrics of recall, precision and ARI (Adjusted Rand Index), d2SBin$$ {d}_2^S\mathrm{Bin} $$ improves the binning performance in 28 out of 30 testing experiments (6 datasets with 5 binning tools). The d2SBin$$ {d}_2^S\mathrm{Bin} $$ is available at https://github.com/kunWangkun/d2SBin.ConclusionsExperiments showed that d2S$$ {d}_2^S $$ accurately measures the dissimilarity between contigs of metagenomic reads and that relative sequence composition is more reasonable to bin the contigs. The d2SBin$$ {d}_2^S\mathrm{Bin} $$ can be applied to any existing contig-binning tools for single metagenomic samples to obtain better binning results.},
author = {Ying Wang and Kun Wang and Yang Young Lu and Fengzhu Sun},
journal = {BMC Bioinformatics},
volume = {18},
pages = {1-14},
doi = {10.1186/s12859-017-1835-1},
pmid = {28931373},
}

@article{350f06ca486a5d3dcce1617549e0292ba884893f,
title = {MetaBAT 2: an adaptive binning algorithm for robust and efficient genome reconstruction from metagenome assemblies},
year = {2019},
url = {https://semanticscholar.org/paper/350f06ca486a5d3dcce1617549e0292ba884893f},
abstract = {We previously reported on MetaBAT, an automated metagenome binning software tool to reconstruct single genomes from microbial communities for subsequent analyses of uncultivated microbial species. MetaBAT has become one of the most popular binning tools largely due to its computational efficiency and ease of use, especially in binning experiments with a large number of samples and a large assembly. MetaBAT requires users to choose parameters to fine-tune its sensitivity and specificity. If those parameters are not chosen properly, binning accuracy can suffer, especially on assemblies of poor quality. Here, we developed MetaBAT 2 to overcome this problem. MetaBAT 2 uses a new adaptive binning algorithm to eliminate manual parameter tuning. We also performed extensive software engineering optimization to increase both computational and memory efficiency. Comparing MetaBAT 2 to alternative software tools on over 100 real world metagenome assemblies shows superior accuracy and computing speed. Binning a typical metagenome assembly takes only a few minutes on a single commodity workstation. We therefore recommend the community adopts MetaBAT 2 for their metagenome binning experiments. MetaBAT 2 is open source software and available at https://bitbucket.org/berkeleylab/metabat.},
author = {Dongwan D Kang and Feng  Li and Edward  Kirton and Ashleigh  Thomas and Rob  Egan and Hong  An and Zhong  Wang},
journal = {PeerJ},
volume = {7},
pages = {},
doi = {10.7717/PEERJ.7359},
pmid = {31388474},
}

@article{de6b66013fcebf03d997d28b384497a1d3733670,
title = {Minimum information about a single amplified genome (MISAG) and a metagenome-assembled genome (MIMAG) of bacteria and archaea},
year = {2017},
url = {https://www.semanticscholar.org/paper/de6b66013fcebf03d997d28b384497a1d3733670},
abstract = {We present two standards developed by the Genomic Standards Consortium (GSC) for reporting bacterial and archaeal genome sequences. Both are extensions of the Minimum Information about Any (x) Sequence (MIxS). The standards are the Minimum Information about a Single Amplified Genome (MISAG) and the Minimum Information about a Metagenome-Assembled Genome (MIMAG), including, but not limited to, assembly quality, and estimates of genome completeness and contamination. These standards can be used in combination with other GSC checklists, including the Minimum Information about a Genome Sequence (MIGS), Minimum Information about a Metagenomic Sequence (MIMS), and Minimum Information about a Marker Gene Sequence (MIMARKS). Community-wide adoption of MISAG and MIMAG will facilitate more robust comparative genomic analyses of bacterial and archaeal diversity.},
author = {R. M. Bowers and N. Kyrpides and R. Stepanauskas and Miranda Harmon-Smith and Devin F R Doud and T. Reddy and F. Schulz and J. Jarett and A. Rivers and E. Eloe-Fadrosh and S. Tringe and Natalia N. Ivanova and A. Copeland and Alicia Clum and Eric D. Becraft and R. Malmstrom and B. Birren and M. Podar and P. Bork and G. Weinstock and G. Garrity and J. Dodsworth and S. Yooseph and G. Sutton and F. Gloeckner and J. Gilbert and W. Nelson and S. Hallam and S. Jungbluth and T. Ettema and S. Tighe and K. Konstantinidis and Wen-Tso Liu and B. Baker and T. Rattei and J. Eisen and B. Hedlund and K. McMahon and N. Fierer and R. Knight and R. Finn and G. Cochrane and I. Karsch-Mizrachi and G. Tyson and Christian Rinke and A. Lapidus and Folker Meyer and Pelin Yilmaz and Donovan H. Parks and A. M. Eren and L. Schriml and J. Banfield and P. Hugenholtz and T. Woyke},
journal = {Nature Biotechnology},
volume = {35},
pages = {725 - 731},
doi = {10.1038/nbt.3893},
pmid = {28787424},
}

@article{3da72117d181a5b4860638eb559f5152ec7be0af,
title = {A two-phase binning algorithm using l-mer frequency on groups of non-overlapping reads},
year = {2015},
url = {https://www.semanticscholar.org/paper/3da72117d181a5b4860638eb559f5152ec7be0af},
abstract = {An unsupervised algorithm for binning of reads from different species in a metagenomic dataset, called BiMeta, which does not require any reference database. BackgroundMetagenomics is the study of genetic materials derived directly from complex microbial samples, instead of from culture. One of the crucial steps in metagenomic analysis, referred to as “binning”, is to separate reads into clusters that represent genomes from closely related organisms. Among the existing binning methods, unsupervised methods base the classification on features extracted from reads, and especially taking advantage in case of the limitation of reference database availability. However, their performance, under various aspects, is still being investigated by recent theoretical and empirical studies. The one addressed in this paper is among those efforts to enhance the accuracy of the classification.ResultsThis paper presents an unsupervised algorithm, called BiMeta, for binning of reads from different species in a metagenomic dataset. The algorithm consists of two phases. In the first phase of the algorithm, reads are grouped into groups based on overlap information between the reads. The second phase merges the groups by using an observation on l-mer frequency distribution of sets of non-overlapping reads. The experimental results on simulated and real datasets showed that BiMeta outperforms three state-of-the-art binning algorithms for both short and long reads (≥700 bp) datasets.ConclusionsThis paper developed a novel and efficient algorithm for binning of metagenomic reads, which does not require any reference database. The software implementing the algorithm and all test datasets mentioned in this paper can be downloaded at http://it.hcmute.edu.vn/bioinfo/bimeta/index.htm.},
author = {L. Vinh and T. Lang and Le Binh and T. Hoai},
doi = {10.1186/s13015-014-0030-4},
pmid = {25648210},
}

@article{d5aed9ecab9996ba61c5b4ad263cb9ff47713677,
title = {Improving metagenomic binning results with overlapped bins using assembly graphs},
year = {2021},
url = {https://www.semanticscholar.org/paper/d5aed9ecab9996ba61c5b4ad263cb9ff47713677},
abstract = {Background Metagenomic sequencing allows us to study the structure, diversity and ecology in microbial communities without the necessity of obtaining pure cultures. In many metagenomics studies, the reads obtained from metagenomics sequencing are first assembled into longer contigs and these contigs are then binned into clusters of contigs where contigs in a cluster are expected to come from the same species. As different species may share common sequences in their genomes, one assembled contig may belong to multiple species. However, existing tools for binning contigs only support non-overlapped binning, i.e., each contig is assigned to at most one bin (species). Results In this paper, we introduce GraphBin2 which refines the binning results obtained from existing tools and, more importantly, is able to assign contigs to multiple bins. GraphBin2 uses the connectivity and coverage information from assembly graphs to adjust existing binning results on contigs and to infer contigs shared by multiple species. Experimental results on both simulated and real datasets demonstrate that GraphBin2 not only improves binning results of existing tools but also supports to assign contigs to multiple bins. Conclusion GraphBin2 incorporates the coverage information into the assembly graph to refine the binning results obtained from existing binning tools. GraphBin2 also enables the detection of contigs that may belong to multiple species. We show that GraphBin2 outperforms its predecessor GraphBin on both simulated and real datasets. GraphBin2 is freely available at https://github.com/Vini2/GraphBin2 .},
author = {V. Mallawaarachchi and A. Wickramarachchi and Yu Lin},
journal = {Algorithms for Molecular Biology : AMB},
volume = {16},
pages = {},
doi = {10.1186/s13015-021-00185-6},
pmid = {33947431},
}

@article{973976782959ed4c0350818ea19bf2cd6adc34f4,
title = {CoMet: a workflow using contig coverage and composition for binning a metagenomic sample with high precision},
year = {2017},
url = {https://www.semanticscholar.org/paper/973976782959ed4c0350818ea19bf2cd6adc34f4},
abstract = {BackgroundIn metagenomics, the separation of nucleotide sequences belonging to an individual or closely matched populations is termed binning. Binning helps the evaluation of underlying microbial population structure as well as the recovery of individual genomes from a sample of uncultivable microbial organisms. Both supervised and unsupervised learning methods have been employed in binning; however, characterizing a metagenomic sample containing multiple strains remains a significant challenge.In this study, we designed and implemented a new workflow, Coverage and composition based binning of Metagenomes (CoMet), for binning contigs in a single metagenomic sample. CoMet utilizes coverage values and the compositional features of metagenomic contigs. The binning strategy in CoMet includes the initial grouping of contigs in guanine-cytosine (GC) content-coverage space and refinement of bins in tetranucleotide frequencies space in a purely unsupervised manner. With CoMet, the clustering algorithm DBSCAN is employed for binning contigs. The performances of CoMet were compared against four existing approaches for binning a single metagenomic sample, including MaxBin, Metawatt, MyCC (default) and MyCC (coverage) using multiple datasets including a sample comprised of multiple strains.ResultsBinning methods based on both compositional features and coverages of contigs had higher performances than the method which is based only on compositional features of contigs. CoMet yielded higher or comparable precision in comparison to the existing binning methods on benchmark datasets of varying complexities. MyCC (coverage) had the highest ranking score in F1-score. However, the performances of CoMet were higher than MyCC (coverage) on the dataset containing multiple strains. Furthermore, CoMet recovered contigs of more species and was 18 - 39% higher in precision than the compared existing methods in discriminating species from the sample of multiple strains. CoMet resulted in higher precision than MyCC (default) and MyCC (coverage) on a real metagenome.ConclusionsThe approach proposed with CoMet for binning contigs, improves the precision of binning while characterizing more species in a single metagenomic sample and in a sample containing multiple strains. The F1-scores obtained from different binning strategies vary with different datasets; however, CoMet yields the highest F1-score with a sample comprised of multiple strains.},
author = {Damayanthi Herath and Sen-Lin Tang and Kshitij Tandon and D. Ackland and S. Halgamuge},
journal = {BMC Bioinformatics},
volume = {18},
pages = {},
doi = {10.1186/s12859-017-1967-3},
pmid = {29297295},
}

@article{d2a5da7f2a9ea95bca72c8af6c8e495a57fee1b8,
title = {BMC3C: binning metagenomic contigs using codon usage, sequence composition and read coverage},
year = {2018},
url = {https://www.semanticscholar.org/paper/d2a5da7f2a9ea95bca72c8af6c8e495a57fee1b8},
abstract = {Motivation: Metagenomics investigates the DNA sequences directly recovered from environmental samples. It often starts with reads assembly, which leads to contigs rather than more complete genomes. Therefore, contig binning methods are subsequently used to bin contigs into genome bins. While some clustering‐based binning methods have been developed, they generally suffer from problems related to stability and robustness. Results: We introduce BMC3C, an ensemble clustering‐based method, to accurately and robustly bin contigs by making use of DNA sequence Composition, Coverage across multiple samples and Codon usage. BMC3C begins by searching the proper number of clusters and repeatedly applying the k‐means clustering with different initializations to cluster contigs. Next, a weight graph with each node representing a contig is derived from these clusters. If two contigs are frequently grouped into the same cluster, the weight between them is high, and otherwise low. BMC3C finally employs a graph partitioning technique to partition the weight graph into subgraphs, each corresponding to a genome bin. We conduct experiments on both simulated and real‐world datasets to evaluate BMC3C, and compare it with the state‐of‐the‐art binning tools. We show that BMC3C has an improved performance compared to these tools. To our knowledge, this is the first time that the codon usage features and ensemble clustering are used in metagenomic contig binning. Availability and implementation: The codes of BMC3C are available at http://mlda.swu.edu.cn/codes.php?name=BMC3C. Supplementary information: Supplementary data are available at Bioinformatics online.},
author = {Guoxian Yu and Yuan Jiang and Jun Wang and H. Zhang and Haiwei Luo},
journal = {Bioinformatics},
volume = {34},
pages = {4172–4179},
doi = {10.1093/bioinformatics/bty519},
pmid = {29947757},
}

@article{850c42e620db08cda7bf4f7cf4d25d6275d7b87b,
title = {Binning unassembled short reads based on k-mer abundance covariance using sparse coding},
year = {2020},
url = {https://www.semanticscholar.org/paper/850c42e620db08cda7bf4f7cf4d25d6275d7b87b},
abstract = {Abstract Background Sequence-binning techniques enable the recovery of an increasing number of genomes from complex microbial metagenomes and typically require prior metagenome assembly, incurring the computational cost and drawbacks of the latter, e.g., biases against low-abundance genomes and inability to conveniently assemble multi-terabyte datasets. Results We present here a scalable pre-assembly binning scheme (i.e., operating on unassembled short reads) enabling latent genome recovery by leveraging sparse dictionary learning and elastic-net regularization, and its use to recover hundreds of metagenome-assembled genomes, including very low-abundance genomes, from a joint analysis of microbiomes from the LifeLines DEEP population cohort (n = 1,135, >1010 reads). Conclusion We showed that sparse coding techniques can be leveraged to carry out read-level binning at large scale and that, despite lower genome reconstruction yields compared to assembly-based approaches, bin-first strategies can complement the more widely used assembly-first protocols by targeting distinct genome segregation profiles. Read enrichment levels across 6 orders of magnitude in relative abundance were observed, indicating that the method has the power to recover genomes consistently segregating at low levels.},
author = {Olexiy O. Kyrgyzov and V. Prost and S. Gazut and Bruno Farcy and T. Brüls},
journal = {GigaScience},
volume = {9},
pages = {},
doi = {10.1093/gigascience/giaa028},
pmid = {32219339},
}

@article{0b127c77daee987267b8811dd97b25bb6bf06fec,
title = {A Novel Binning Algorithm Using Topic Modelling and k-mer Frequency on Groups of Non-Overlapping Short Reads},
year = {2020},
url = {https://www.semanticscholar.org/paper/0b127c77daee987267b8811dd97b25bb6bf06fec},
abstract = {Metagenomics is a field that studies the microorganisms from the environment itself instead of traditional culturing methods. In this paper, we focus on the binning problem, which is to group reads into clusters that highly represent a taxonomic group. The result of this step serves as a crucial input for the next one of a metagenomic project such as assembly and annotation. Because metagenomic reads does not have explicit features, it is not easy to divide them into distinct groups. The solutions for this binning problem can be categorized as supervised and unsupervised approaches. Supervised ones need a reference database, which is unfortunately about 1% of the microorganisms in nature. This prevents these approaches from working well with the dataset that contain unknown species. In this paper we follow an unsupervised approach. Our proposed method is to combine the result from another technique named BiMeta, which based on a biological signature assumption that reads of a same taxonomic label have a same k-mer distribution, and topic modelling as a way of reducing the dimensions of the dataset. Our method shows better results (by precision, recall, and F-measure) than BiMeta on most datasets. Although following BiMeta, LDABiMeta out- performs it with the new proposed ideas. Moreover, our method is equiv- alent to MetaProb, which is the most successful method at present time, for the short-read datasets.},
author = {Hoang D. Quach and H. T. Lam and Dang H. N. Nguyen and Phuong V. D. Van and Van Hoai Tran},
journal = {2020 5th International Conference on Green Technology and Sustainable Development (GTSD)},
volume = {},
pages = {380-386},
doi = {10.1109/GTSD50082.2020.9303095},
}

@article{97f1b4464d43b4824ca509a4a7f5cfad29e63dc1,
title = {Marginalised stack denoising autoencoders for metagenomic data binning},
year = {2017},
url = {https://www.semanticscholar.org/paper/97f1b4464d43b4824ca509a4a7f5cfad29e63dc1},
abstract = {Shotgun sequencing has facilitated the analysis of complex microbial communities. Recently we have shown how local binary patterns (LBP) from image processing can be used to analyse the sequenced samples. LBP codes represent the data in a sparse high dimensional space. To improve the performance of our pipeline, marginalised stacked autoencoders are used here to learn frequent LBP codes and map the high dimensional space to a lower dimension dense space. We demonstrate its performance using both low and high complexity simulated metagenomic data and compare the performance of our method with several existing techniques including principal component analysis (PCA) in the dimension reduction step and fc-mer frequency in feature extraction step.},
author = {S. Kouchaki and Santosh Tirunagari and Avraam Tapinos and D. Robertson},
journal = {2017 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)},
volume = {},
pages = {1-6},
doi = {10.1109/CIBCB.2017.8058552},
}

@article{ba7d27b16f42eff6359624f7a654c0f77a18815f,
title = {Local binary patterns as a feature descriptor in alignment-free visualisation of metagenomic data},
year = {2016},
url = {https://www.semanticscholar.org/paper/ba7d27b16f42eff6359624f7a654c0f77a18815f},
abstract = {Shotgun sequencing has facilitated the analysis of complex microbial communities. However, clustering and visualising these communities without prior taxonomic information is a major challenge. Feature descriptor methods can be utilised to extract these taxonomic relations from the data. Here, we present a novel approach consisting of local binary patterns (LBP) coupled with randomised singular value decomposition (RSVD) and Barnes-Hut t-stochastic neighbor embedding (BH-tSNE) to highlight the underlying taxonomic structure of the metagenomic data. The effectiveness of our approach is demonstrated using several simulated and a real metagenomic datasets.},
author = {S. Kouchaki and Santosh Tirunagari and Avraam Tapinos and D. Robertson},
journal = {2016 IEEE Symposium Series on Computational Intelligence (SSCI)},
volume = {},
pages = {1-6},
doi = {10.1109/SSCI.2016.7849955},
}
