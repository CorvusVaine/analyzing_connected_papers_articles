@article{901cd053fc72fda279698344ad13605a712f4249,
title = {DeepBiome: a phylogenetic tree informed deep neural network for microbiome data analysis},
year = {2020},
url = {https://www.semanticscholar.org/paper/901cd053fc72fda279698344ad13605a712f4249},
abstract = {
 Background: Evidence linking microbiome and human health is rapidly growing. Microbiome profile can be a novel predictive biomarker for many diseases. However, bacteria count tables are typically sparse and bacteria are classified at a hierarchy of taxonomic levels, ranging from species to phylum. Existing analysis tools focus on identifying microbiome associations either at the community level or at a specific pre-defined taxonomic level. They fail to incorporate the evolutionary relationship between bacteria and cannot learn from the data to aggregate microbiome contribution, thus leading to less accurate and less interpretable results in prediction, classification or selection. Results: We present DeepBiome, a phylogney-informed neural network architecture for predicting phenotypes from microbiome counts and uncovering the microbiome-phenotype association network. It takes microbiome abundance as the input and let the phylogenetic taxonomy guide the neural network architecture. Commonly used neural network architectures are targeted towards image and text analysis and typically require huge amount of training data, which is scarce in biomedical applications. By leveraging the phylogenetic information, DeepBiome relieves the heavy burden of tuning for the optimal deep learning architecture, avoids overfitting, and more importantly enables visualizing the path from microbiome counts to disease. It is applicable to both regression and classification problems. The simulation study and real-life data analysis demonstrate that DeepBiome is highly accurate and efficient and and provides a deep understanding of complex microbiome-phenotype associations even using small to moderate training sample sizes. Conclusions: In practice, it is unknown at which taxonomic level that microbiome clusters tag the association. Therefore, the central advantage of the presented method over other analytical methods is that it offers an ecological and evolutionary understanding of host-microbe interactions which is important for microbiome-based medicine. DeepBiome is implemented using Python packages Keras and the Tensorflow. It is an open-source tool available at (https://github.com/Young-won/DeepBiome).},
author = {Jing Zhai and Youngwon Choi and Yin Chen and K. Knox and H. Iii and Won Joong-Ho and Hua Zhou and Jin J. Zhou},
doi = {10.21203/rs.3.rs-33860/v1},
}

@article{a5c9417ac06d62df8e4c6379d35c6a2fb70f91b3,
title = {FACIAL EXPRESSION CLASSIFIER BASED ON MACHINE LEARNING ALGORITHMS},
year = {2018},
url = {https://www.semanticscholar.org/paper/a5c9417ac06d62df8e4c6379d35c6a2fb70f91b3},
abstract = {Sentiment analysis is a hot topic nowadays, an algorithm extracts subjective information from users, and helps a business to monitor the social reaction toward certain product or service. Sentiment can be extracted from different sources, e.g. speech, text, images. In this document, we are going to focus on computer vision algorithms using images as input data. In recent years, convolutional neural networks (CNN) have become the state-of-art deep learning models in image recognition. They have the power of deep learning as well as optimized feature extraction capabilities. CNNs are considered the top most accurate models in last decade, and new architectures are constantly being developed. This paper proposes several convolutional neural network designs, trained with the greatest public dataset in facial expression, AffectNet, with over 420K manually labeled images. Once the model is trained and tested, the most accurate model is deployed in Affective, a photo manager application capable of classifying stored images in any android device according to 8 facial expressions.},
author = {Valero Puche and Llobet Azpitarte},
}

@article{1c882ed4b461ea4222ccafde3d9b6251158d2d72,
title = {Dynamic Coattention Networks with Encoder Maxout},
year = {2017},
url = {https://www.semanticscholar.org/paper/1c882ed4b461ea4222ccafde3d9b6251158d2d72},
abstract = {We implement a system based on the Dynamic Coattention Network outlined in Xiong et al. to address the Stanford Question Answering Dataset (SQuAD), learning to find continuous answer spans for prompted questions contained in a context document. We further experiment with variations on the original architecture, including the use of BiLSTMs and the addition of a maxout layer in the coattention encoder. We find that our attempts to simultaneously incorporate BiLSTMs and avoid a significant increase in the number of parameters result in reduced performance. We also find that the encoder maxout layer provides a small but consistent performance boost. Our final model incorporates the encoder maxout layer and obtains a test set F1 score of 69.22% and EM of 58.764%.},
author = {Thaminda Edirisooriya and Morgan Tenney and Han-Gyu Kim},
}

@article{35efdde26ae75feb014d93e7a3754f5faac932d3,
title = {Shallow SqueezeNext: Real Time Deployment on Bluebox2.0 with 272KB Model Size},
year = {2020},
url = {https://www.semanticscholar.org/paper/35efdde26ae75feb014d93e7a3754f5faac932d3},
abstract = {The significant challenges for deploying CNNs/DNNs on ADAS are limited computation and memory resources with very limited efficiency. Design space exploration of CNNs or DNNS, training and testing DNN from scratch, hyper parameter tuning, implementation with different optimizers contributed towards the efficiency and performance improvement of the Shallow SqueezeNext architecture. It is also computationally efficient, inexpensive and requires minimum memory resources. It achieves better model size and speed in comparison to other counterparts such as AlexNet, VGGnet, SqueezeNet, and SqueezeNext, trained and tested from scratch on datasets such as CIFAR-10 and CIFAR-100. It can achieve the least model size of 272KB with a model accuracy of 82%, a model speed of 9 seconds per epoch, and tested on the CIFAR-10 dataset. It achieved the best accuracy of 91.41%, best model size of 0.272 MB, and best model speed of 4 seconds per epoch. Memory resources are of high importance when it comes down to real time system or platforms because usually the memory is quite limited. To verify that the Shallow SqueezeNext can be successfully deployed on a real time platform, bluebox2.0 by NXP was used. Bluebox2.0 deployment of Shallow SqueezeNext architecture achieved a model accuracy of 90.50%, 8.72MB model size and 22 seconds per epoch model speed. There is another version of the Shallow SqueezeNext which performed better that attained a model size of 0.5MB with model accuracy of 87.30% and 11 seconds per epoch model speed trained and tested from scratch on CIFAR-10 dataset.},
author = {Jayan Kant Duggal and M. El-Sharkawy},
doi = {10.11648/J.JEEE.20200806.11},
}

@article{083576a4c9548cec32555d3efad6351558391ccb,
title = {CLASSIFICATION OF UNDERWATER PIPELINE EVENTS USING DEEP CONVOLUTIONAL NEURAL NETWORKS},
year = {2017},
url = {https://www.semanticscholar.org/paper/083576a4c9548cec32555d3efad6351558391ccb},
abstract = {A inspecao automatica de dutos submarinos tem sido uma tarefa de crescente importância para a deteccao de diferentes tipos de eventos, dos quais destacam-se armadura exposta, presenca de algas, flanges e manta. Tais inspecoes podem se beneficiar de tecnicas de aprendizado de maquinas para classificar acuradamente essas ocorrencias. Neste trabalho, apresenta-se um algoritmo de redes neurais convolucionais para classificacao de eventos em dutos submarinos. A arquitetura e os parâmetros da rede neural que resultam em desempenho de classificacao otimo sao selecionados. A tecnica de rede neural convolucional, em comparacao ao algoritmo do perceptron precedido por extracao de features wavelet, apresenta desempenho superior para diferentes classes de eventos, alcancando em media acuracia de classificacao de 93.2%, enquanto o desempenho alcancado pelo perceptron e de 91.2%. Alem dos resultados obtidos no conjunto de teste, sao analisadas as curvas de acuracia e de entropia cruzada obtidas para o conjunto de validacao ao longo do treinamento, de modo a comparar os desempenhos de cada metodo e para cada classe de eventos. Sao tambem fornecidas visualizacoes das saidas das camadas intermediarias da rede convolucional. Essas visualizacoes sao interpretadas e associadas aos resultados obtidos.},
author = {J. Gomes},
}

@article{1cee5163619313416485e553d82f925e4b006057,
title = {IMPLEMENTATION OF HUMAN FACE AND SPOOFING DETECTION USING DEEP LEARNING ON EMBEDDED HARDWARE},
year = {2020},
url = {https://www.semanticscholar.org/paper/1cee5163619313416485e553d82f925e4b006057},
abstract = {R. Abhishek Department of Electronics and Communication (ECE) Vnit-Nagpur. ...................................................................................................................... Manuscript Info Abstract ......................... ........................................................................ Manuscript History Received: 05 April 2020 Final Accepted: 07 May 2020 Published: June 2020},
author = {R. Abhishek},
doi = {10.21474/ijar01/11121},
}

@article{6718b454a20343f7fac06d44ad6539c1531ebc19,
title = {Application of fault tolerant calculation in small-footprint keyword spotting neural network},
year = {2019},
url = {https://www.semanticscholar.org/paper/6718b454a20343f7fac06d44ad6539c1531ebc19},
abstract = {In recent years, many applications of voice wake-up technology have entered peoples field of vision. The key technology is Keyword Spotting. The system needs to detect the ambient voice waiting for a wake-up at any time, so it requires a low hardware energy and high recognition accuracy. This paper aims at real-time speech keyword detection applications. Based on Googles open source speech commands dataset and Librispeech dataset, combined with various fault-tolerant calculations, a deep neural network that suitable for low-power integrated circuits are constructed and trained. The main structure of the network is the Depthwise Convolution Network (DSC). The energy consumption and resource overhead of the model in hardware implementation is reduced by combining various fault-tolerant calculation methods such as approximation addition, quantification, and binarization. The fault tolerance of the model is improved through retraining method. We proved that the fault-tolerant calculation method of quantization with approximation addition has great potential in small-footprint keyword spotting neural network.},
author = {Yicheng Lu and Weiwei Shan and Jiaming Xu},
}

@article{a767db882de72ab9741876dcefe63dec224fa2bb,
title = {Towards a New Deep Learning Algorithm Based on GRU and CNN: NGRU},
year = {2021},
url = {https://www.semanticscholar.org/paper/a767db882de72ab9741876dcefe63dec224fa2bb},
abstract = {This paper describes our new deep learning system based on a comparison between GRU and CNN. Initially we start with the first system which uses Convolutional Neural Network (CNN) which we will compare with the second system which uses Gated Recurrent Unit (GRU). And through this comparison we propose a new system based on the positive points of the two previous systems. Therefore, this new system will take the right choice of hyper-parameters recommended by the authors of both systems. At the final stage we propose a method to apply this new system to the dataset of different languages (used especially in socials networks).},
author = {Abdelhamid Atassi and I. E. Azami},
doi = {10.14313/JAMRIS/4-2020/44},
}

@article{0bfee3b65f11558332584655efcc30eec28d9ac1,
title = {Backpropagation method modification using Taylor series to improve accuracy of offline neural network training},
year = {2021},
url = {https://www.semanticscholar.org/paper/0bfee3b65f11558332584655efcc30eec28d9ac1},
abstract = {},
author = {A. Glushchenko and V. Petrov and K. Lastochkin},
doi = {10.1016/J.PROCS.2021.04.139},
}

@article{f0d717967b63b535f53dae13c73aa2541eb28667,
title = {An in depth analysis of neural network with application in finance},
year = {2019},
url = {https://www.semanticscholar.org/paper/f0d717967b63b535f53dae13c73aa2541eb28667},
abstract = {Artificial neural network model is inspired from how the nervous system of brain works. If it is designed properly it can process large amount of data or information and can give proper output for different application like pattern recognition, forecasting disease or financial data etc. In recent years Artificial neural network has been a great choice to analyze financial time series data as they are quite capable of learning the relationships among different features of data. As the world’s economy is continuously changing, there is a need for keep an eye on the dynamic conditions of economy. Therefore, financial institutions and investors always wants a reliable system to monitor the data relationship so that they can simulate and predict financial positions on the basis of market trends in order to find where should they invest. But because of the high volatility and high non linearity it has been quite a challenge to predict the financial stock market. In this paper we attempt to study neural network and how they are actually useful in predicting stock market and finally we are going to use different model of ANN to predict the stock price of Amazon and SP 500 index. We will analyze the capability of neural net to cope with the nonlinear and chaotic patterns of data and their ability to predict.},
author = {Noshin Tasnim and Farhana Yasmeen},
}

@article{143fde5f421fe6fde9014e9e928d456e13ddb780,
title = {Stance Detection for Fake News Identification},
year = {2017},
url = {https://www.semanticscholar.org/paper/143fde5f421fe6fde9014e9e928d456e13ddb780},
abstract = {The latest election cycle generated sobering examples of the threat that fake news poses to democracy. Primarily disseminated by hyper-partisan media outlets, fake news proved capable of becoming viral sensations that can dominate social media and influence elections. To address this problem, we begin with stance detection, which is a first step towards identifying fake news. The goal of this project is to identify whether given headline-article pairs: (1) agree, (2) disagree, (3) discuss the same topic, or (4) are not related at all, as described in [1]. Our method feeds the headline-article pairs into a bidirectional LSTM which first analyzes the article and then uses the acquired article representation to analyze the headline. On top of the output of the conditioned bidirectional LSTM, we concatenate global statistical features extracted from the headline-article pairs. We report a 9.7% improvement in the Fake News Challenge evaluation metric and a 22.7% improvement in mean F1 compared to the highest scoring baseline. We also present qualitative results that show how our method outperforms state-of-the art algorithms on this challenge.},
author = {Damian Mrowca},
}

@article{55f4fd0fa6335720df9bd74ce4102a8656c9592c,
title = {Phase Conductor on Multi-layered Attentions for Machine Comprehension},
year = {2017},
url = {https://www.semanticscholar.org/paper/55f4fd0fa6335720df9bd74ce4102a8656c9592c},
abstract = {Attention models have been intensively studied to improve NLP tasks such as machine comprehension via both question-aware passage attention model and self-matching attention model. Our research proposes phase conductor (PhaseCond) for attention models in two meaningful ways. First, PhaseCond, an architecture of multi-layered attention models, consists of multiple phases each implementing a stack of attention layers producing passage representations and a stack of inner or outer fusion layers regulating the information flow. Second, we extend and improve the dot-product attention function for PhaseCond by simultaneously encoding multiple question and passage embedding layers from different perspectives. We demonstrate the effectiveness of our proposed model PhaseCond on the SQuAD dataset, showing that our model significantly outperforms both state-of-the-art single-layered and multiple-layered attention models. We deepen our results with new findings via both detailed qualitative analysis and visualized examples showing the dynamic changes through multi-layered attention models.},
author = {R. Liu and Wei Wei and Weiguang Mao and M. Chikina},
arxivid = {1710.10504},
}

@article{7d5615fe1541c98fbb517c230949ad0b0bd84456,
title = {CAESAR : Context-Awareness Enabled and Summary-Attentive Reader},
year = {2017},
url = {https://www.semanticscholar.org/paper/7d5615fe1541c98fbb517c230949ad0b0bd84456},
abstract = {Comprehending meaning from natural language is the primary objective of Natural Language Processing(NLP), and text comprehension definitely is the cornerstone for achieving this objective upon which all other problems like chat bots, language translation and others can be modeled in some way or the other. In this report, we first present a brief analysis of some of the state of the art(SOTA) solutions for the problem of Reading Comprehension using the recently published Stanford Question Answering Dataset (SQuAD) [1]. Next we detail our implementation of two of these models: Match LSTM [2] and Dynamic Coattention Networks [3]. We also describe our attempts of using the recently developed attention mechanism constructs, sequence to sequence learning(seq2seq) [4]. Our best trained model reached close to matching the results obtained by these advanced solutions. Finally, we describe our novel attempt of employing a summary attentive reader which tries to make the training process efficient yet retaining the same scores.},
author = {Kshitiz Tripathi and Long-Huei Chen},
}

@article{45e1d75e5a51674fa41eb5e021289f2938728698,
title = {# SQuADGoals : A Comparative Analysis of Models for Closed Domain Question Answering},
year = {2017},
url = {https://www.semanticscholar.org/paper/45e1d75e5a51674fa41eb5e021289f2938728698},
abstract = {The task of machine comprehension has long been one of the greatest unsolved tasks in natural language processing. Thanks to a proliferation of datasets, numerous deep neural architectures have been created. We implemented two such architectures: the Match-LSTM with Answer Pointer[1] and a flavor of Dynamic Coattention Networks[2]. Our end-to-end models are able to exceed an existing logistic regression baseline with millions of derived features without having to perform any feature extraction, demonstrating the neural architectures are well poised to be the dominant model for conquering QA.},
author = {Andrew Duffy and Daniel Shiferaw and Eric Musyoka},
}

@article{adfd824da32849941e87ece541eeeed2c0459705,
title = {SQuAD Reading Comprehension with Coattention},
year = {2017},
url = {https://www.semanticscholar.org/paper/adfd824da32849941e87ece541eeeed2c0459705},
abstract = {Reading comprehension is an important task in NLP, which involves teaching a machine to understand text enough to answer questions. The Stanford Question Answering Dataset (SQuAD) is a dataset consisting of 100,000 question-context-answer datapoints. Here, deep learning methods are used to answer questions based on context data. A model based on the Attentive Reader [1,2] model is used as a baseline, with elements of a Dynamic Coattention Network [3] applied. Co-dependent attention representations that combine the individual representations of the question and context paragraph are implemented. The model is evaluated using F1 and exact match (EM) scores.},
author = {Austin Hou},
}

@article{61487711b15a69c367ca759820350622ba57c6d8,
title = {Conditioning LSTM Decoder and Bi-directional Attention Based Question Answering System},
year = {2019},
url = {https://www.semanticscholar.org/paper/61487711b15a69c367ca759820350622ba57c6d8},
abstract = {Applying neural-networks on Question Answering has gained increasing popularity in recent years. In this paper, I implemented a model with Bi-directional attention flow layer, connected with a Multi-layer LSTM encoder, connected with one start-index decoder and one conditioning end-index decoder. I introduce a new end-index decoder layer, conditioning on start-index output. The Experiment shows this has increased model performance by 15.16%. For prediction, I proposed a new smart-span equation, rewarding both short answer length and high probability in start-index and end-index, which further improved the prediction accuracy. The best single model achieves an F1 score of 73.97% and EM score of 64.95% on test set.},
author = {Heguang Liu},
arxivid = {1905.02019},
}

@article{1f3b7429e2b92ad97cc4209f68b1fa879d6f5b2f,
title = {Extended QA System on SQuAD 2 . 0},
year = {2021},
url = {https://www.semanticscholar.org/paper/1f3b7429e2b92ad97cc4209f68b1fa879d6f5b2f},
abstract = {Our motivation is to build a Question Answering (QA) system that gives answers as specific and as accurate to queries, which is in itself an art but based on the science of Natural Language Processing (NLP). Some efforts have been made to either increase the scale of the dataset (semi-annotation, SQUAD), or to improve the NLP structure (Statistical QA, Neural QA). The main goal of our project is to produce a QA system that works well on SQUAD 2.0 dataset that performs better than the baseline Bidirectional Attention Flow (BiDAF) model. To better capture the context from a more expressive set of answers and understand the interactions between the question and the document, we utilized the coattention mechanism by encoding the two-way attention outputs together through a bidirectional reccurrent neural network (RNN). For our main finding, we aim to implement the mechanisms that would improve upon the baseline method under the Exact Match (EM) and the F1 scores. In the experiment, our best performing single model obtained a F1 score of 63.40 and an EM score of 59.87 which both achieved better results than the baseline. To further improve the performance of our model, we built ensemble model that achieved EM of 60.81 and F1 of 64.21.},
author = {L. Hao and Yi and Wei},
}

@article{e94697b98b707f557436e025bdc8498fa261d3bc,
title = {Multi-Perspective Context Matching for Machine Comprehension},
year = {2016},
url = {https://www.semanticscholar.org/paper/e94697b98b707f557436e025bdc8498fa261d3bc},
abstract = {Previous machine comprehension (MC) datasets are either too small to train end-to-end deep learning models, or not difficult enough to evaluate the ability of current MC techniques. The newly released SQuAD dataset alleviates these limitations, and gives us a chance to develop more realistic MC models. Based on this dataset, we propose a Multi-Perspective Context Matching (MPCM) model, which is an end-to-end system that directly predicts the answer beginning and ending points in a passage. Our model first adjusts each word-embedding vector in the passage by multiplying a relevancy weight computed against the question. Then, we encode the question and weighted passage by using bi-directional LSTMs. For each point in the passage, our model matches the context of this point against the encoded question from multiple perspectives and produces a matching vector. Given those matched vectors, we employ another bi-directional LSTM to aggregate all the information and predict the beginning and ending points. Experimental result on the test set of SQuAD shows that our model achieves a competitive result on the leaderboard.},
author = {Zhiguo Wang and Haitao Mi and W. Hamza and Radu Florian},
arxivid = {1612.04211},
}

@article{5927c2170fb03f9f34ef886c65fdf2cc6ec34089,
title = {Assignment 4 : Question Answering on the SQuAD Dataset with Part-of-speech Tagging},
year = {2017},
url = {https://www.semanticscholar.org/paper/5927c2170fb03f9f34ef886c65fdf2cc6ec34089},
abstract = {This research applies deep learning with bi-LSTMs to train a model that responds to queries on the Stanford Question Answering Dataset (SQuAD). The model design was motivated by Wang et. al.’s December 2016 IBM Research paper on multi-perspective context matching for machine comprehension. Using TensorFlow, we implemented a multi-layer neural network architecture utilizing bi-directional LSTMs and context-based processing to maximize scores in the dataset. Our model achieves a performance of 61% F1 on the hidden test despite its small number of parameters, and offers room for improvement in multiple directions.},
author = {Joan Creus-Costa and Philip Hwang},
}

@article{280c483458f034c5361f94d1a01021c2ba7104d1,
title = {Extending a BiDAF model with DCN for Question Answering},
year = {2021},
url = {https://www.semanticscholar.org/paper/280c483458f034c5361f94d1a01021c2ba7104d1},
abstract = {Our goal in this project is to improve the performance of the Bidirectional Attention Flow (BiDAF) model for the NLP task of question answering on the SQuAD 2.0 dataset. To do this, we 1) integrate character-level embeddings into the baseline BiDAF model and 2) replace the default attention layer with a coattention layer. While adding character-level embeddings has shown to improve the baseline BiDAF model’s EM and F1 scores substantially, their addition to the DCN model actually decreased its scores slightly. Moreover, transforming the BiDAF model into a Dynamic Coattention Network (DCN) decreased the model’s performance. Thus, the best model architecture we found is BiDAF with character-level embeddings. Future work includes tuning hyperparameters, experimenting with data processing techniques, adding optimizations like the Adam optimizer, and exploring different forms of attention.},
author = {Michelle Xing and Hanna Yip},
}

@article{761fc49e501145d2d1f6a2105a9893967c4c89bd,
title = {Question Answering on the SQuAD Dataset},
year = {2017},
url = {https://www.semanticscholar.org/paper/761fc49e501145d2d1f6a2105a9893967c4c89bd},
abstract = {We develop a deep learning framework for question answering on the Stanford Question Answering Dataset (SQuAD), blending ideas from existing state-of-theart models to achieve results that surpass the original logistic regression baselines. Using a dynamic coattention encoder and an LSTM decoder, we achieved an F1 score of 55.9% on the hidden SQuAD test set. In this paper, we present the methodology governing our question answering model. In addition, we critically analyze potential shortcomings and limitations of our algorithm and others in the literature and propose extensions for future work to push the boundaries of question answering further. The SQuAD Task Machine question answering remains one of the most important problems in artificial intelligence and natural language processing for both its rich potential in numerous applications requiring information synthesis and knowledge retrieval as well as its inherent difficulty, testing the boundaries of computers to process human language. Because of the added difficulty in parsing text to draw meaningful conclusions, question answering has emerged as a very fertile area for advancements in end-to-end deep learning models and innovations in natural language processing techniques. In the past decade, several datasets for question answering tasks have been proposed. These resources, while valuable towards the end-goal of training question-answering systems, all experience a considerable tradeoff between data quality and size. Some older datasets, such as those of Berant, et al. and Richardson, et al. use human curated questions and effectively capture the nuances of natural language, but – due to the labor involved in generating the questions– are often insufficient for training robust machine learning models for the task. Conversely, datasets generated via automation, such as those of Hermann, et al. and Hill, et al. lack the structure of authentic human language and, as a result, lose the ability to test for the core skills involved in reading comprehension. Moreover, many of these older datasets employ multiple choice or single-word formats for the ground-truth answers which inherently limits the ability of models to learn linguistic structure when formulating answers. In response to the shortcomings of these previous question answering datasets, Rajpurkar, et al. released the Stanford Question Answering Dataset (SQuAD) in 2016. Utilizing questions generated from 536 Wikipedia articles by a team of crowdworkers, SQuAD consists of over 100,000 rows of data – far exceeding the size of similar datasets – in the form of a question, an associated Wikipedia context paragraph containing the answer to the question, and the answer. The ground-truth answer labels are represented in the form of two indices, a start index as and an end index ae, which represent words in the context paragraph.},
author = {Dongju Park},
}

@article{636c28c6ac08df538b8e98b82b752bdf20cf7fa8,
title = {Question Answering on SQuAD 2 . 0},
year = {2021},
url = {https://www.semanticscholar.org/paper/636c28c6ac08df538b8e98b82b752bdf20cf7fa8},
abstract = {The goal of this project is to build a Question Answering system on the SQuAD 2.0 dataset. Our initial approach to solve this problem focused on implementing the default baseline model that is based on a variant of Bidirectional Attention Flow (BiDAF) with attention. We explored performance after adding character level embeddings to the baseline along with exploring various attention mechanisms. Additionally, we also explored the impact of tuning the hyper-parameters used to train the model. Finally, we studied the effect of using multiple variants of RNN as building blocks in the neural architecture.},
author = {Aditya Srivastava and A. Rao},
}

@article{dabf6549dd2bddd610434d1184f80a0c76d4df26,
title = {A Question-Focused Multi-Factor Attention Network for Question Answering},
year = {2018},
url = {https://www.semanticscholar.org/paper/dabf6549dd2bddd610434d1184f80a0c76d4df26},
abstract = {
 
 Neural network models recently proposed for question answering (QA) primarily focus on capturing the passage-question relation. However, they have minimal capability to link relevant facts distributed across multiple sentences which is crucial in achieving deeper understanding, such as performing multi-sentence reasoning, co-reference resolution, etc. They also do not explicitly focus on the question and answer type which often plays a critical role in QA. In this paper, we propose a novel end-to-end question-focused multi-factor attention network for answer extraction. Multi-factor attentive encoding using tensor-based transformation aggregates meaningful facts even when they are located in multiple sentences. To implicitly infer the answer type, we also propose a max-attentional question aggregation mechanism to encode a question vector based on the important words in a question. During prediction, we incorporate sequence-level encoding of the first wh-word and its immediately following word as an additional source of question type information. Our proposed model achieves significant improvements over the best prior state-of-the-art results on three large-scale challenging QA datasets, namely NewsQA, TriviaQA, and SearchQA.
 
},
author = {Souvik Kundu and H. Ng},
doi = {10.1609/aaai.v32i1.12065},
arxivid = {1801.08290},
}

@article{91e2ad42e708f3c4bcd6940552e435f4bb56e628,
title = {Neural Network-based Question Answering System},
year = {2017},
url = {https://www.semanticscholar.org/paper/91e2ad42e708f3c4bcd6940552e435f4bb56e628},
abstract = {The idea of a Question Answering (QA) system is to extract information (sometimes passages, or spans of words) directly from documents, conversations, online searches, etc., that will meet the user's information needs. In this work, we focus on the Stanford Question Answering Dataset (SQuAD) and propose an end-toend deep neural network model for machine comprehension, while achieving an F1 score of 61.13% and an Exact Match (EM) score of 46.92% on the test dataset. Codalab submission username: goyalk F1 score on test dataset: 61.13% EM score on test dataset: 46.92%},
author = {Kushaagra Goyal and Sanyam Mehra},
}

@article{84311ccc1fdbf43cc4862d3fa27032980008e43a,
title = {CS 224 N Assignment 4 : Reading Comprehension},
year = {2017},
url = {https://www.semanticscholar.org/paper/84311ccc1fdbf43cc4862d3fa27032980008e43a},
abstract = {This assignment can be completed in groups of up to 3 people. We encourage groups to work together productively so that all students understand the submitted system well. We ask that you abide by the university Honor Code and that of the Computer Science department, and make sure that all of your submitted work (except as acknoweldged) is done by yourself and your team members only. It is fine to take ideas from other papers on reading comprehension, but you should acknowledge them in your write-up.},
author = {Christina Kao-chris},
}

@article{3f1b62c9bd2b8b60c603895b7b1005a014edeac0,
title = {BiDAF Pro Max for Question Answering System},
year = {2022},
url = {https://www.semanticscholar.org/paper/3f1b62c9bd2b8b60c603895b7b1005a014edeac0},
abstract = {As one of the ultimate goals of natural language processing, machine comprehension (MC) can be assessed by answering one or multiple questions with a chunk of text. In order to improve the performance of our model on SQuAD 2.0, we explore different embedding operations (character embeddings, token features), attention mechanism (iterative reattention) and output prediction structures (con-ditioning prediction) based on the baseline model, compared with QANet. Our results show that token features signiﬁcantly improve the prediction by raising F1 score and EM score by >10; the iterative attention mechanism could further improve the model, achieving F1=81.65 and EM=77.89 on dev examples, F1=76.63 and EM=73.27 on test examples.},
author = {Kendrick Shen and Zhengguan Dai and Qingyue Wei and Yitao Qiu},
}

@article{4c16a6fd7b4aad8c1331e4753b30701fdf6d12f4,
title = {Neural Domain Adaptation for Biomedical Question Answering},
year = {2017},
url = {https://www.semanticscholar.org/paper/4c16a6fd7b4aad8c1331e4753b30701fdf6d12f4},
abstract = {Factoid question answering (QA) has recently benefited from the development of deep learning (DL) systems. Neural network models outperform traditional approaches in domains where large datasets exist, such as SQuAD (ca. 100,000 questions) for Wikipedia articles. However, these systems have not yet been applied to QA in more specific domains, such as biomedicine, because datasets are generally too small to train a DL system from scratch. For example, the BioASQ dataset for biomedical QA comprises less then 900 factoid (single answer) and list (multiple answers) QA instances. In this work, we adapt a neural QA system trained on a large open-domain dataset (SQuAD, source) to a biomedical dataset (BioASQ, target) by employing various transfer learning techniques. Our network architecture is based on a state-of-the-art QA system, extended with biomedical word embeddings and a novel mechanism to answer list questions. In contrast to existing biomedical QA systems, our system does not rely on domain-specific ontologies, parsers or entity taggers, which are expensive to create. Despite this fact, our systems achieve state-of-the-art results on factoid questions and competitive results on list questions.},
author = {Georg Wiese and Dirk Weissenborn and Mariana Neves},
doi = {10.18653/v1/K17-1029},
arxivid = {1706.03610},
}

@article{f5734d2a9f090be0031c9eba6c70e1a0ed1cbd2f,
title = {SQuAD Reading Comprehension},
year = {2018},
url = {https://www.semanticscholar.org/paper/f5734d2a9f090be0031c9eba6c70e1a0ed1cbd2f},
abstract = {One important task in Natural Language Understanding is Reading Comprehension. Given a piece of text, we want to be able to answer any relevant questions. Using Stanford Question Answering Dataset(SQuAD), which is a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, we built a reading comprehension model that attains 75.2% F1 score and 65.0% Exact Match (EM) on the test set.},
author = {Xinyi Jiang},
}

@article{02607f5d3c7638d0207279d96f39d435f102bf4d,
title = {Assignment 4: Reading Comprehension},
year = {2017},
url = {https://www.semanticscholar.org/paper/02607f5d3c7638d0207279d96f39d435f102bf4d},
abstract = {Reading comprehension is the task of understanding a piece of text by a machine. We train an end-to-end neural network that models the conditional distribution of start and end indices, given the question and context paragraph. We build on top of the baseline suggested in the Assignment, and explore new models to implement attention. We also measure the performance of the models and analyse the reason for improved performance over the baseline.},
author = {Vishakh Hegde},
}

@article{45e9e33a541480b30120fd9d29e0d39240a3d32f,
title = {Alpha and Omega? Gauging the influence of Answer-Pointer Frameworks in Question Answering Models},
year = {2022},
url = {https://www.semanticscholar.org/paper/45e9e33a541480b30120fd9d29e0d39240a3d32f},
abstract = {Answer-Pointer RNNs have factored into successful machine comprehension models, especially those designed for the SQUaD challenge. However, whether or not these RNNs may be applied, generally, to boost model performance is unclear. In our project, we perform an ablation study to isolate the precise performance benefits of these Answer-Pointer RNN components in different models. We observe the improvements of an Answer-Pointer RNN on a baseline BiDAF model, a BiDAF model with character embeddings, and a BiDAF model with a self-attention encoding layer, after the R-net model (1). We introduce a novel output layer that combines succesful elements of the BiDAF and R-net models (2). The Answer-Pointer output contributed to improved performance in some models, but worse performance in others. We conclude that an Answer-Pointer RNN must be applied with careful regularization, and propose that they may be less effective in models that leverage gratuitous self attention.},
author = {Nicholas Paul Brazeau Sanchez},
}

@article{f89f7474933604fcb0bc10c891c1ac6f02d8af83,
title = {Coattention-Based Neural Network for Question Answering},
year = {2017},
url = {https://www.semanticscholar.org/paper/f89f7474933604fcb0bc10c891c1ac6f02d8af83},
abstract = {Machine comprehension (MC) and question answering (QA) are related NLP tasks which have seen increased interest with the recent release of the Stanford Question Answering Dataset (SQuAD). In this paper, we explore a neural architecture for the QA task which is based largely on the coattention encoder proposed by Xiong et al. [1]. After encoding the data with a context-aware representation of the question and question-aware representation of the context, we decode using simple linear decoders to construct the final probability distributions for the answer location within the context paragraph. Our best single model achieves an F1 score of 70.0% on the withheld test dataset, while an ensemble achieves 74.1% F1.},
author = {Jim Andress and Cristian Zanoci CodaLab},
}

@article{d01118671156d75ebc39da18ea8a23e4422a3c49,
title = {Attention-aware attention ( A * ) : combining coattention and self-attention for question answering},
year = {2021},
url = {https://www.semanticscholar.org/paper/d01118671156d75ebc39da18ea8a23e4422a3c49},
abstract = {Attention has been one of the biggest recent breakthrough in NLP, paving the way for the improvement of state-of-art models in many tasks. In question answering, it has been successfully applied under many forms, especially with recurrent models (encoder-decoder fashion). Co-attention [1] and multihead self-attention [2] have been two interesting attention variations, but a larger study trying to combine them has never been conducted to the best of our knowledge. Hence, the purpose of this paper is to experiment different attention-based architecture types for question answering, as variations from one of the first successful recurrent encoder-decoder models for this task: BiDAF [3]. We test the performance of our model on the Stanford Question Answering Dataset 2.0 [4] and achieved a performance of EM = 62.730 and F1 = 66.283 on the dev set, and EM = 60.490 and F1 = 64.081 on the test set.},
author = {},
}

@article{525f65936c331b0b766c7aea0eae64c595704c50,
title = {Mnemonic Reader for Machine Comprehension},
year = {2017},
url = {https://www.semanticscholar.org/paper/525f65936c331b0b766c7aea0eae64c595704c50},
abstract = {Recently, several end-to-end neural models have been proposed for machine comprehension tasks. Typically, these models use attention mechanisms to capture the complicated interaction between the context and the query and then point the boundary of answer. To better point the correct answer, we introduce the Mnemonic Reader for machine comprehension tasks, which enhance the attention reader in two aspects. Firstly, we use a self-alignment attention to model the long-distance dependency among context words, and obtain query-aware and selfaware contextual representation for each word in the context. Second, we use a memory-based query-dependent pointer to predict the answer, which integrates both explicit and implicit query information, such as query category. Our experimental evaluations show that our model obtains the state-of-the-art result on the large-scale machine comprehension benchmarks SQuAD.},
author = {Minghao Hu and Yuxing Peng and Xipeng Qiu},
}

@article{6a796c1c9c30913cb24d64939f90dcb06fa82be7,
title = {Simple Dynamic Coattention Networks},
year = {2017},
url = {https://www.semanticscholar.org/paper/6a796c1c9c30913cb24d64939f90dcb06fa82be7},
abstract = {Reading comprehension (RC), or the capability to process document texts and answer questions about them is a difficult task for machines, as human language understanding and real-world knowledge are needed [4]. This can serve a wide range of applications, from simplifying information retrieval processes to building more robust artificial intelligence. Previously, most natural language processing was done with classical probabilistic models. With the recent progress in deep learning, more researchers are switching to using neural networks as they are proven to produce better results.},
author = {Wenqin Wu},
}

@article{aeafb3b4f6a685645a749294cdd68b7ab552596f,
title = {A simple sequence attention model for machine comprehension},
year = {2017},
url = {https://www.semanticscholar.org/paper/aeafb3b4f6a685645a749294cdd68b7ab552596f},
abstract = {Machine comprehension is an important NLP problem with a number of important applications. Particularly question answering has been attracting a lot of attention on the applied research area. This work explores a simple sequence attention architecture for question answering. In this work the Stanford Question and Answering Dataset (SQuAD) introduced by Rajpurkar et al. (2016) is employed.},
author = {Marcello Hasegawa},
}

@article{22ca480fec5a3c2af1963fd57e2f7a54e040ef58,
title = {Building a QA System using R-net},
year = {2021},
url = {https://www.semanticscholar.org/paper/22ca480fec5a3c2af1963fd57e2f7a54e040ef58},
abstract = {Question-answering (QA) task is an important problem for research in natural language processing, for which many deep learning models have been designed. In this report we implement R-Net and evaluate its performance on SQUAD 2.0. While the performance of R-Net itself is worse than BiDAF, it showed a strong capability of its attention mechanism. We have also experimented with an ensemble model using BiDAF and R-Net that achieved better performance than the baseline BiDAF. Our study suggests that a promising future direction is to combine BiDAF and R-Net for building better models. 1 Key Information to include ¢ Mentor: Lingjue Xie},
author = {Tianyi Liu},
}

@article{8a2b78ef8dd8f779226c1fe378ef3494fad12c97,
title = {Question Answering Using Regularized Match-LSTM and Answer Pointer},
year = {2017},
url = {https://www.semanticscholar.org/paper/8a2b78ef8dd8f779226c1fe378ef3494fad12c97},
abstract = {Automated reading comprehension is an important problem in natural language processing. The Stanford Question Answering Dataset (SQuAD) is a convenient set of questions and crowdsourced answers to utilize for evaluation of QA systems. In this paper, we implement a version of an architecture proposed by Wang and Jiang (2016) based on match-LSTM [9], a model used for textual entailment, and answer candidate generation based on Pointer Net (Vinyals et al., 2015) [7]. We extend the original implementation with an investigation of the effect of regularization methods on this task. Specifically, we argue that any amount of regularization via dropout improves test performance because it prevents overfitting; however, we also note that varying the dropout probability does not significantly change performance, provided it is sufficiently far from 1 (< 0.8).},
author = {Ellen Blaine},
}

@article{3574fc19671188279bb07a8bf5e6d6dbb3bc7e5e,
title = {SQuAD Question Answering Problem : A match-lstm implementation},
year = {2017},
url = {https://www.semanticscholar.org/paper/3574fc19671188279bb07a8bf5e6d6dbb3bc7e5e},
abstract = {As a first experience in neural network modeling, and tensor flow usage, we try to implement a match-LSTM attention model, which is known for achieving interesting results on the SQuaD dataset leader board.},
author = {P. Fraisse},
}

@article{56df00594e6fc3bba9e2e196c26af1f4e5a0b2cf,
title = {Multitask Learning and Extensions of Dynamic Coattention Network},
year = {2017},
url = {https://www.semanticscholar.org/paper/56df00594e6fc3bba9e2e196c26af1f4e5a0b2cf},
abstract = {Dynamic Coattention Network (DCN) was introduced in late 2016 and achieved state-of-the-art performance on Stanford Question Answering Dataset (SQuAD). In this paper, we re-implement DCN and explore different extensions to DCN, including multi-task learning with Quora question pairs dataset, different loss function that account for distance from truth, variation of sentinel vectors, novel pre-processing trick, modification to coattention encoder architecture, as well as hyperparameter tuning. After joint training, we observe a 2% increase in f1 on Quora dataset. Our conclusion is that multi-task learning benefits the simpler task more than the more complicated task. On CodaLab leaderboard, we achieved Test f1 = 67.282, EM = 56.278.},
author = {Keven Kedao},
}

@article{5d16decec17ee3831a9f4161d63dcf8a9dd07ded,
title = {Reading Comprehension on the SQuAD Dataset},
year = {2017},
url = {https://www.semanticscholar.org/paper/5d16decec17ee3831a9f4161d63dcf8a9dd07ded},
abstract = {Reading comprehension is a challenging task for machine learning, since the system must be able to model complex interactions between the question and the context paragraph. For this task, I reimplemented the Bidirectional Attention Flow model and linked the two BiLSTMs in the contextual embed layer. A single model achieved 74.524% F1 and 64.261% EM on the test set. The ensemble of seven models achieved 77.465% F1 and 68.478% EM. The model achieved competitive rank on the class leaderboard, despite having 4% lower score than the original implementation.},
author = {Fnu Budianto},
}

@article{b561e606a74885a1c0e768874a6436e5c995eea4,
title = {A Nil-Aware Answer Extraction Framework for Question Answering},
year = {2018},
url = {https://www.semanticscholar.org/paper/b561e606a74885a1c0e768874a6436e5c995eea4},
abstract = {Recently, there has been a surge of interest in reading comprehension-based (RC) question answering (QA). However, current approaches suffer from an impractical assumption that every question has a valid answer in the associated passage. A practical QA system must possess the ability to determine whether a valid answer exists in a given text passage. In this paper, we focus on developing QA systems that can extract an answer for a question if and only if the associated passage contains an answer. If the associated passage does not contain any valid answer, the QA system will correctly return Nil. We propose a novel nil-aware answer span extraction framework that is capable of returning Nil or a text span from the associated passage as an answer in a single step. We show that our proposed framework can be easily integrated with several recently proposed QA models developed for reading comprehension and can be trained in an end-to-end fashion. Our proposed nil-aware answer extraction neural network decomposes pieces of evidence into relevant and irrelevant parts and then combines them to infer the existence of any answer. Experiments on the NewsQA dataset show that the integration of our proposed framework significantly outperforms several strong baseline systems that use pipeline or threshold-based approaches.},
author = {Souvik Kundu and H. Ng},
doi = {10.18653/v1/D18-1456},
}
